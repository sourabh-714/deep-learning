{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upMalStOb_DL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AINVEEI3cBU6"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from google.colab import files\n",
    "upload=files.upload()\n",
    "df=pd.read_csv(io.BytesIO(data_to_load['Churn_Modelling.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "pySLWM3-ef8z",
    "outputId": "826a75b3-9f78-49e9-e305-c99a641042c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
       "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
       "1          2    15647311      Hill  ...               1       112542.58      0\n",
       "2          3    15619304      Onio  ...               0       113931.57      1\n",
       "3          4    15701354      Boni  ...               0        93826.63      0\n",
       "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "bnfqht1yccvP",
    "outputId": "579862b3-76d0-4748-8e82-ecd2d71c1b9f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId  Surname  ...  IsActiveMember  EstimatedSalary  Exited\n",
       "0         False       False    False  ...           False            False   False\n",
       "1         False       False    False  ...           False            False   False\n",
       "2         False       False    False  ...           False            False   False\n",
       "3         False       False    False  ...           False            False   False\n",
       "4         False       False    False  ...           False            False   False\n",
       "...         ...         ...      ...  ...             ...              ...     ...\n",
       "9995      False       False    False  ...           False            False   False\n",
       "9996      False       False    False  ...           False            False   False\n",
       "9997      False       False    False  ...           False            False   False\n",
       "9998      False       False    False  ...           False            False   False\n",
       "9999      False       False    False  ...           False            False   False\n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "O1c_wrfIdyZ2",
    "outputId": "67a6b9e7-481d-4ed1-bf9b-600739cd1dbd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId  ...  EstimatedSalary        Exited\n",
       "count  10000.00000  1.000000e+04  ...     10000.000000  10000.000000\n",
       "mean    5000.50000  1.569094e+07  ...    100090.239881      0.203700\n",
       "std     2886.89568  7.193619e+04  ...     57510.492818      0.402769\n",
       "min        1.00000  1.556570e+07  ...        11.580000      0.000000\n",
       "25%     2500.75000  1.562853e+07  ...     51002.110000      0.000000\n",
       "50%     5000.50000  1.569074e+07  ...    100193.915000      0.000000\n",
       "75%     7500.25000  1.575323e+07  ...    149388.247500      0.000000\n",
       "max    10000.00000  1.581569e+07  ...    199992.480000      1.000000\n",
       "\n",
       "[8 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "y0BiauMpuFgw",
    "outputId": "07bec7e0-ad28-4d0a-8fc3-c4c7ffe4e1af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2c263aa160>"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#EDA\n",
    "import seaborn as sns\n",
    "sns.boxplot(x='Gender',y='Exited',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "3Mud27nqv8rg",
    "outputId": "4ad50247-ee37-489a-d9b4-dfc0836d5ed3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2c1d842588>"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x='IsActiveMember',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "5z8INlTmu2Dj",
    "outputId": "56c28f56-c56f-4cd8-d507-f1b13ce09ae0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10000 artists>"
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Comparing Salaries on the basis of Gender\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(x='Gender',height='EstimatedSalary',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APbEyP6XvbSw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0CQMahed7O7"
   },
   "outputs": [],
   "source": [
    "x=df.drop(['CustomerId','Surname','Geography','Gender','Exited'],axis=1)\n",
    "y=df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iI_1037Ge8bC"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXKhJYxQe-at"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcuip6GWfkHN",
    "outputId": "c6aa61bc-a392-4dd7-c762-824631f3aa4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc=MinMaxScaler()\n",
    "sc.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jSxM61TgYyy"
   },
   "outputs": [],
   "source": [
    "x_train=sc.transform(x_train)\n",
    "x_test=sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AfhALwXngw-u"
   },
   "outputs": [],
   "source": [
    "#creating model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyM8OdlviVgV"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBZwTa1Jhp32"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(units=10,activation='relu'))\n",
    "model.add(Dense(units=5,activation='relu'))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25dyoE4oicUS",
    "outputId": "cc7a63c3-8438-4e93-9051-c1efc3b78436"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5251 - accuracy: 0.7890 - val_loss: 0.4777 - val_accuracy: 0.8080\n",
      "Epoch 2/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7909 - val_loss: 0.4655 - val_accuracy: 0.8080\n",
      "Epoch 3/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7915 - val_loss: 0.4567 - val_accuracy: 0.8080\n",
      "Epoch 4/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7993 - val_loss: 0.4492 - val_accuracy: 0.8080\n",
      "Epoch 5/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.7941 - val_loss: 0.4339 - val_accuracy: 0.8165\n",
      "Epoch 6/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.8036 - val_loss: 0.4228 - val_accuracy: 0.8245\n",
      "Epoch 7/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.8129 - val_loss: 0.4228 - val_accuracy: 0.8240\n",
      "Epoch 8/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8137 - val_loss: 0.4098 - val_accuracy: 0.8285\n",
      "Epoch 9/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4213 - accuracy: 0.8239 - val_loss: 0.4099 - val_accuracy: 0.8280\n",
      "Epoch 10/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.8054 - val_loss: 0.3997 - val_accuracy: 0.8320\n",
      "Epoch 11/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8192 - val_loss: 0.3956 - val_accuracy: 0.8320\n",
      "Epoch 12/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.8193 - val_loss: 0.3907 - val_accuracy: 0.8345\n",
      "Epoch 13/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4166 - accuracy: 0.8244 - val_loss: 0.3871 - val_accuracy: 0.8370\n",
      "Epoch 14/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8308 - val_loss: 0.3838 - val_accuracy: 0.8390\n",
      "Epoch 15/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8365 - val_loss: 0.3815 - val_accuracy: 0.8410\n",
      "Epoch 16/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8298 - val_loss: 0.3857 - val_accuracy: 0.8355\n",
      "Epoch 17/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8316 - val_loss: 0.3747 - val_accuracy: 0.8410\n",
      "Epoch 18/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3905 - accuracy: 0.8371 - val_loss: 0.3725 - val_accuracy: 0.8430\n",
      "Epoch 19/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8449 - val_loss: 0.3690 - val_accuracy: 0.8440\n",
      "Epoch 20/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8358 - val_loss: 0.3665 - val_accuracy: 0.8460\n",
      "Epoch 21/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8371 - val_loss: 0.3709 - val_accuracy: 0.8485\n",
      "Epoch 22/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3829 - accuracy: 0.8374 - val_loss: 0.3616 - val_accuracy: 0.8535\n",
      "Epoch 23/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.8377 - val_loss: 0.3587 - val_accuracy: 0.8505\n",
      "Epoch 24/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8350 - val_loss: 0.3563 - val_accuracy: 0.8500\n",
      "Epoch 25/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8492 - val_loss: 0.3568 - val_accuracy: 0.8490\n",
      "Epoch 26/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3724 - accuracy: 0.8431 - val_loss: 0.3537 - val_accuracy: 0.8555\n",
      "Epoch 27/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8365 - val_loss: 0.3518 - val_accuracy: 0.8560\n",
      "Epoch 28/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8469 - val_loss: 0.3523 - val_accuracy: 0.8570\n",
      "Epoch 29/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8445 - val_loss: 0.3506 - val_accuracy: 0.8560\n",
      "Epoch 30/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8462 - val_loss: 0.3524 - val_accuracy: 0.8590\n",
      "Epoch 31/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8490 - val_loss: 0.3607 - val_accuracy: 0.8520\n",
      "Epoch 32/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8456 - val_loss: 0.3544 - val_accuracy: 0.8560\n",
      "Epoch 33/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8466 - val_loss: 0.3516 - val_accuracy: 0.8580\n",
      "Epoch 34/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8367 - val_loss: 0.3524 - val_accuracy: 0.8560\n",
      "Epoch 35/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8524 - val_loss: 0.3484 - val_accuracy: 0.8650\n",
      "Epoch 36/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8489 - val_loss: 0.3491 - val_accuracy: 0.8620\n",
      "Epoch 37/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8514 - val_loss: 0.3572 - val_accuracy: 0.8505\n",
      "Epoch 38/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8475 - val_loss: 0.3564 - val_accuracy: 0.8550\n",
      "Epoch 39/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8443 - val_loss: 0.3487 - val_accuracy: 0.8640\n",
      "Epoch 40/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3666 - accuracy: 0.8463 - val_loss: 0.3471 - val_accuracy: 0.8625\n",
      "Epoch 41/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8555 - val_loss: 0.3482 - val_accuracy: 0.8625\n",
      "Epoch 42/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8455 - val_loss: 0.3469 - val_accuracy: 0.8625\n",
      "Epoch 43/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8508 - val_loss: 0.3469 - val_accuracy: 0.8620\n",
      "Epoch 44/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8363 - val_loss: 0.3460 - val_accuracy: 0.8620\n",
      "Epoch 45/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8516 - val_loss: 0.3462 - val_accuracy: 0.8640\n",
      "Epoch 46/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3532 - accuracy: 0.8548 - val_loss: 0.3458 - val_accuracy: 0.8635\n",
      "Epoch 47/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8425 - val_loss: 0.3440 - val_accuracy: 0.8655\n",
      "Epoch 48/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8514 - val_loss: 0.3485 - val_accuracy: 0.8625\n",
      "Epoch 49/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8553 - val_loss: 0.3473 - val_accuracy: 0.8660\n",
      "Epoch 50/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8508 - val_loss: 0.3452 - val_accuracy: 0.8625\n",
      "Epoch 51/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8520 - val_loss: 0.3475 - val_accuracy: 0.8640\n",
      "Epoch 52/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8575 - val_loss: 0.3448 - val_accuracy: 0.8595\n",
      "Epoch 53/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8496 - val_loss: 0.3448 - val_accuracy: 0.8625\n",
      "Epoch 54/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8523 - val_loss: 0.3460 - val_accuracy: 0.8660\n",
      "Epoch 55/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8474 - val_loss: 0.3426 - val_accuracy: 0.8645\n",
      "Epoch 56/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8435 - val_loss: 0.3428 - val_accuracy: 0.8670\n",
      "Epoch 57/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8568 - val_loss: 0.3448 - val_accuracy: 0.8635\n",
      "Epoch 58/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8482 - val_loss: 0.3443 - val_accuracy: 0.8660\n",
      "Epoch 59/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8481 - val_loss: 0.3429 - val_accuracy: 0.8635\n",
      "Epoch 60/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8499 - val_loss: 0.3424 - val_accuracy: 0.8660\n",
      "Epoch 61/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8566 - val_loss: 0.3440 - val_accuracy: 0.8665\n",
      "Epoch 62/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8582 - val_loss: 0.3422 - val_accuracy: 0.8635\n",
      "Epoch 63/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8469 - val_loss: 0.3444 - val_accuracy: 0.8615\n",
      "Epoch 64/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8530 - val_loss: 0.3443 - val_accuracy: 0.8640\n",
      "Epoch 65/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8534 - val_loss: 0.3436 - val_accuracy: 0.8655\n",
      "Epoch 66/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8530 - val_loss: 0.3414 - val_accuracy: 0.8650\n",
      "Epoch 67/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8554 - val_loss: 0.3458 - val_accuracy: 0.8625\n",
      "Epoch 68/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8580 - val_loss: 0.3447 - val_accuracy: 0.8660\n",
      "Epoch 69/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8576 - val_loss: 0.3421 - val_accuracy: 0.8620\n",
      "Epoch 70/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8540 - val_loss: 0.3428 - val_accuracy: 0.8655\n",
      "Epoch 71/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8502 - val_loss: 0.3442 - val_accuracy: 0.8615\n",
      "Epoch 72/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8500 - val_loss: 0.3422 - val_accuracy: 0.8665\n",
      "Epoch 73/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8493 - val_loss: 0.3453 - val_accuracy: 0.8585\n",
      "Epoch 74/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3499 - accuracy: 0.8587 - val_loss: 0.3417 - val_accuracy: 0.8655\n",
      "Epoch 75/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8483 - val_loss: 0.3424 - val_accuracy: 0.8655\n",
      "Epoch 76/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8506 - val_loss: 0.3417 - val_accuracy: 0.8675\n",
      "Epoch 77/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8525 - val_loss: 0.3443 - val_accuracy: 0.8630\n",
      "Epoch 78/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8524 - val_loss: 0.3421 - val_accuracy: 0.8660\n",
      "Epoch 79/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8543 - val_loss: 0.3403 - val_accuracy: 0.8670\n",
      "Epoch 80/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3711 - accuracy: 0.8517 - val_loss: 0.3408 - val_accuracy: 0.8660\n",
      "Epoch 81/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8578 - val_loss: 0.3510 - val_accuracy: 0.8625\n",
      "Epoch 82/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8492 - val_loss: 0.3409 - val_accuracy: 0.8655\n",
      "Epoch 83/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.8542 - val_loss: 0.3403 - val_accuracy: 0.8650\n",
      "Epoch 84/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8533 - val_loss: 0.3419 - val_accuracy: 0.8665\n",
      "Epoch 85/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8526 - val_loss: 0.3420 - val_accuracy: 0.8645\n",
      "Epoch 86/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8496 - val_loss: 0.3412 - val_accuracy: 0.8630\n",
      "Epoch 87/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8467 - val_loss: 0.3408 - val_accuracy: 0.8650\n",
      "Epoch 88/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8560 - val_loss: 0.3403 - val_accuracy: 0.8670\n",
      "Epoch 89/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8460 - val_loss: 0.3397 - val_accuracy: 0.8660\n",
      "Epoch 90/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8575 - val_loss: 0.3443 - val_accuracy: 0.8635\n",
      "Epoch 91/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8595 - val_loss: 0.3410 - val_accuracy: 0.8640\n",
      "Epoch 92/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8574 - val_loss: 0.3467 - val_accuracy: 0.8605\n",
      "Epoch 93/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8585 - val_loss: 0.3509 - val_accuracy: 0.8585\n",
      "Epoch 94/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8577 - val_loss: 0.3403 - val_accuracy: 0.8645\n",
      "Epoch 95/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8467 - val_loss: 0.3422 - val_accuracy: 0.8675\n",
      "Epoch 96/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8494 - val_loss: 0.3428 - val_accuracy: 0.8640\n",
      "Epoch 97/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8597 - val_loss: 0.3436 - val_accuracy: 0.8640\n",
      "Epoch 98/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8495 - val_loss: 0.3415 - val_accuracy: 0.8650\n",
      "Epoch 99/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8525 - val_loss: 0.3415 - val_accuracy: 0.8625\n",
      "Epoch 100/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8497 - val_loss: 0.3408 - val_accuracy: 0.8630\n",
      "Epoch 101/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8588 - val_loss: 0.3395 - val_accuracy: 0.8660\n",
      "Epoch 102/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8591 - val_loss: 0.3405 - val_accuracy: 0.8640\n",
      "Epoch 103/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.8573 - val_loss: 0.3414 - val_accuracy: 0.8645\n",
      "Epoch 104/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8549 - val_loss: 0.3404 - val_accuracy: 0.8655\n",
      "Epoch 105/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8583 - val_loss: 0.3408 - val_accuracy: 0.8650\n",
      "Epoch 106/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8605 - val_loss: 0.3412 - val_accuracy: 0.8640\n",
      "Epoch 107/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8533 - val_loss: 0.3417 - val_accuracy: 0.8595\n",
      "Epoch 108/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8468 - val_loss: 0.3415 - val_accuracy: 0.8620\n",
      "Epoch 109/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8490 - val_loss: 0.3417 - val_accuracy: 0.8660\n",
      "Epoch 110/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8596 - val_loss: 0.3385 - val_accuracy: 0.8670\n",
      "Epoch 111/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8592 - val_loss: 0.3494 - val_accuracy: 0.8595\n",
      "Epoch 112/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8583 - val_loss: 0.3437 - val_accuracy: 0.8620\n",
      "Epoch 113/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8437 - val_loss: 0.3455 - val_accuracy: 0.8620\n",
      "Epoch 114/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8540 - val_loss: 0.3436 - val_accuracy: 0.8645\n",
      "Epoch 115/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8541 - val_loss: 0.3388 - val_accuracy: 0.8630\n",
      "Epoch 116/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8535 - val_loss: 0.3391 - val_accuracy: 0.8660\n",
      "Epoch 117/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8562 - val_loss: 0.3390 - val_accuracy: 0.8615\n",
      "Epoch 118/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8542 - val_loss: 0.3387 - val_accuracy: 0.8640\n",
      "Epoch 119/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8554 - val_loss: 0.3381 - val_accuracy: 0.8630\n",
      "Epoch 120/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8580 - val_loss: 0.3385 - val_accuracy: 0.8635\n",
      "Epoch 121/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8494 - val_loss: 0.3400 - val_accuracy: 0.8635\n",
      "Epoch 122/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8529 - val_loss: 0.3404 - val_accuracy: 0.8655\n",
      "Epoch 123/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8547 - val_loss: 0.3413 - val_accuracy: 0.8655\n",
      "Epoch 124/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8539 - val_loss: 0.3382 - val_accuracy: 0.8650\n",
      "Epoch 125/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8604 - val_loss: 0.3489 - val_accuracy: 0.8595\n",
      "Epoch 126/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8591 - val_loss: 0.3398 - val_accuracy: 0.8625\n",
      "Epoch 127/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.8538 - val_loss: 0.3391 - val_accuracy: 0.8630\n",
      "Epoch 128/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8529 - val_loss: 0.3444 - val_accuracy: 0.8650\n",
      "Epoch 129/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8637 - val_loss: 0.3390 - val_accuracy: 0.8640\n",
      "Epoch 130/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8500 - val_loss: 0.3408 - val_accuracy: 0.8665\n",
      "Epoch 131/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8515 - val_loss: 0.3391 - val_accuracy: 0.8610\n",
      "Epoch 132/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8549 - val_loss: 0.3384 - val_accuracy: 0.8665\n",
      "Epoch 133/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8624 - val_loss: 0.3382 - val_accuracy: 0.8660\n",
      "Epoch 134/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8547 - val_loss: 0.3370 - val_accuracy: 0.8640\n",
      "Epoch 135/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8544 - val_loss: 0.3395 - val_accuracy: 0.8640\n",
      "Epoch 136/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8574 - val_loss: 0.3379 - val_accuracy: 0.8660\n",
      "Epoch 137/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8583 - val_loss: 0.3375 - val_accuracy: 0.8645\n",
      "Epoch 138/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8594 - val_loss: 0.3372 - val_accuracy: 0.8660\n",
      "Epoch 139/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8553 - val_loss: 0.3351 - val_accuracy: 0.8670\n",
      "Epoch 140/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8561 - val_loss: 0.3432 - val_accuracy: 0.8660\n",
      "Epoch 141/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8528 - val_loss: 0.3373 - val_accuracy: 0.8650\n",
      "Epoch 142/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8551 - val_loss: 0.3390 - val_accuracy: 0.8655\n",
      "Epoch 143/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8540 - val_loss: 0.3345 - val_accuracy: 0.8640\n",
      "Epoch 144/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8554 - val_loss: 0.3353 - val_accuracy: 0.8620\n",
      "Epoch 145/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8581 - val_loss: 0.3359 - val_accuracy: 0.8620\n",
      "Epoch 146/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8585 - val_loss: 0.3364 - val_accuracy: 0.8640\n",
      "Epoch 147/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8522 - val_loss: 0.3373 - val_accuracy: 0.8625\n",
      "Epoch 148/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8590 - val_loss: 0.3397 - val_accuracy: 0.8635\n",
      "Epoch 149/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8521 - val_loss: 0.3348 - val_accuracy: 0.8595\n",
      "Epoch 150/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8591 - val_loss: 0.3380 - val_accuracy: 0.8655\n",
      "Epoch 151/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8545 - val_loss: 0.3372 - val_accuracy: 0.8670\n",
      "Epoch 152/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8595 - val_loss: 0.3354 - val_accuracy: 0.8680\n",
      "Epoch 153/350\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3583 - accuracy: 0.8478 - val_loss: 0.3332 - val_accuracy: 0.8625\n",
      "Epoch 154/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8543 - val_loss: 0.3361 - val_accuracy: 0.8610\n",
      "Epoch 155/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8632 - val_loss: 0.3396 - val_accuracy: 0.8670\n",
      "Epoch 156/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8511 - val_loss: 0.3346 - val_accuracy: 0.8605\n",
      "Epoch 157/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8540 - val_loss: 0.3354 - val_accuracy: 0.8610\n",
      "Epoch 158/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8495 - val_loss: 0.3340 - val_accuracy: 0.8600\n",
      "Epoch 159/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8493 - val_loss: 0.3332 - val_accuracy: 0.8645\n",
      "Epoch 160/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8622 - val_loss: 0.3426 - val_accuracy: 0.8630\n",
      "Epoch 161/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8563 - val_loss: 0.3333 - val_accuracy: 0.8635\n",
      "Epoch 162/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8585 - val_loss: 0.3338 - val_accuracy: 0.8625\n",
      "Epoch 163/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8596 - val_loss: 0.3372 - val_accuracy: 0.8640\n",
      "Epoch 164/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8576 - val_loss: 0.3429 - val_accuracy: 0.8575\n",
      "Epoch 165/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8470 - val_loss: 0.3336 - val_accuracy: 0.8620\n",
      "Epoch 166/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8533 - val_loss: 0.3358 - val_accuracy: 0.8605\n",
      "Epoch 167/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8594 - val_loss: 0.3383 - val_accuracy: 0.8665\n",
      "Epoch 168/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8584 - val_loss: 0.3373 - val_accuracy: 0.8630\n",
      "Epoch 169/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8484 - val_loss: 0.3362 - val_accuracy: 0.8660\n",
      "Epoch 170/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3489 - accuracy: 0.8566 - val_loss: 0.3371 - val_accuracy: 0.8670\n",
      "Epoch 171/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8608 - val_loss: 0.3353 - val_accuracy: 0.8625\n",
      "Epoch 172/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8575 - val_loss: 0.3357 - val_accuracy: 0.8640\n",
      "Epoch 173/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8536 - val_loss: 0.3353 - val_accuracy: 0.8595\n",
      "Epoch 174/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8563 - val_loss: 0.3440 - val_accuracy: 0.8610\n",
      "Epoch 175/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8536 - val_loss: 0.3385 - val_accuracy: 0.8655\n",
      "Epoch 176/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8552 - val_loss: 0.3370 - val_accuracy: 0.8630\n",
      "Epoch 177/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8534 - val_loss: 0.3394 - val_accuracy: 0.8665\n",
      "Epoch 178/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8545 - val_loss: 0.3383 - val_accuracy: 0.8670\n",
      "Epoch 179/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8490 - val_loss: 0.3352 - val_accuracy: 0.8610\n",
      "Epoch 180/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8600 - val_loss: 0.3359 - val_accuracy: 0.8605\n",
      "Epoch 181/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8633 - val_loss: 0.3360 - val_accuracy: 0.8605\n",
      "Epoch 182/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8540 - val_loss: 0.3340 - val_accuracy: 0.8640\n",
      "Epoch 183/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8590 - val_loss: 0.3370 - val_accuracy: 0.8625\n",
      "Epoch 184/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8545 - val_loss: 0.3365 - val_accuracy: 0.8655\n",
      "Epoch 185/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8550 - val_loss: 0.3353 - val_accuracy: 0.8610\n",
      "Epoch 186/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8615 - val_loss: 0.3358 - val_accuracy: 0.8570\n",
      "Epoch 187/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8638 - val_loss: 0.3378 - val_accuracy: 0.8665\n",
      "Epoch 188/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8605 - val_loss: 0.3358 - val_accuracy: 0.8615\n",
      "Epoch 189/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8551 - val_loss: 0.3372 - val_accuracy: 0.8645\n",
      "Epoch 190/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8600 - val_loss: 0.3375 - val_accuracy: 0.8640\n",
      "Epoch 191/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8611 - val_loss: 0.3347 - val_accuracy: 0.8625\n",
      "Epoch 192/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8534 - val_loss: 0.3368 - val_accuracy: 0.8650\n",
      "Epoch 193/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8555 - val_loss: 0.3392 - val_accuracy: 0.8590\n",
      "Epoch 194/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8584 - val_loss: 0.3342 - val_accuracy: 0.8630\n",
      "Epoch 195/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8579 - val_loss: 0.3375 - val_accuracy: 0.8650\n",
      "Epoch 196/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8575 - val_loss: 0.3371 - val_accuracy: 0.8615\n",
      "Epoch 197/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8491 - val_loss: 0.3373 - val_accuracy: 0.8660\n",
      "Epoch 198/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8476 - val_loss: 0.3336 - val_accuracy: 0.8610\n",
      "Epoch 199/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3483 - accuracy: 0.8556 - val_loss: 0.3388 - val_accuracy: 0.8625\n",
      "Epoch 200/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8582 - val_loss: 0.3392 - val_accuracy: 0.8595\n",
      "Epoch 201/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8538 - val_loss: 0.3382 - val_accuracy: 0.8610\n",
      "Epoch 202/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8597 - val_loss: 0.3381 - val_accuracy: 0.8620\n",
      "Epoch 203/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8579 - val_loss: 0.3346 - val_accuracy: 0.8630\n",
      "Epoch 204/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8618 - val_loss: 0.3368 - val_accuracy: 0.8635\n",
      "Epoch 205/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8551 - val_loss: 0.3342 - val_accuracy: 0.8620\n",
      "Epoch 206/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8591 - val_loss: 0.3377 - val_accuracy: 0.8630\n",
      "Epoch 207/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8550 - val_loss: 0.3401 - val_accuracy: 0.8625\n",
      "Epoch 208/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3506 - accuracy: 0.8586 - val_loss: 0.3352 - val_accuracy: 0.8600\n",
      "Epoch 209/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8633 - val_loss: 0.3348 - val_accuracy: 0.8605\n",
      "Epoch 210/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8600 - val_loss: 0.3400 - val_accuracy: 0.8615\n",
      "Epoch 211/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8553 - val_loss: 0.3350 - val_accuracy: 0.8615\n",
      "Epoch 212/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8556 - val_loss: 0.3411 - val_accuracy: 0.8620\n",
      "Epoch 213/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8565 - val_loss: 0.3409 - val_accuracy: 0.8625\n",
      "Epoch 214/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8641 - val_loss: 0.3354 - val_accuracy: 0.8600\n",
      "Epoch 215/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8590 - val_loss: 0.3395 - val_accuracy: 0.8635\n",
      "Epoch 216/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8576 - val_loss: 0.3339 - val_accuracy: 0.8600\n",
      "Epoch 217/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8472 - val_loss: 0.3355 - val_accuracy: 0.8595\n",
      "Epoch 218/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8495 - val_loss: 0.3342 - val_accuracy: 0.8610\n",
      "Epoch 219/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8505 - val_loss: 0.3369 - val_accuracy: 0.8620\n",
      "Epoch 220/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8590 - val_loss: 0.3383 - val_accuracy: 0.8630\n",
      "Epoch 221/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8588 - val_loss: 0.3382 - val_accuracy: 0.8600\n",
      "Epoch 222/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8579 - val_loss: 0.3357 - val_accuracy: 0.8630\n",
      "Epoch 223/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8653 - val_loss: 0.3404 - val_accuracy: 0.8600\n",
      "Epoch 224/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3540 - accuracy: 0.8557 - val_loss: 0.3368 - val_accuracy: 0.8615\n",
      "Epoch 225/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3478 - accuracy: 0.8555 - val_loss: 0.3371 - val_accuracy: 0.8610\n",
      "Epoch 226/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8522 - val_loss: 0.3367 - val_accuracy: 0.8595\n",
      "Epoch 227/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8525 - val_loss: 0.3348 - val_accuracy: 0.8590\n",
      "Epoch 228/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8561 - val_loss: 0.3382 - val_accuracy: 0.8610\n",
      "Epoch 229/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8594 - val_loss: 0.3395 - val_accuracy: 0.8625\n",
      "Epoch 230/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8578 - val_loss: 0.3347 - val_accuracy: 0.8595\n",
      "Epoch 231/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8621 - val_loss: 0.3406 - val_accuracy: 0.8620\n",
      "Epoch 232/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8626 - val_loss: 0.3389 - val_accuracy: 0.8600\n",
      "Epoch 233/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8521 - val_loss: 0.3394 - val_accuracy: 0.8605\n",
      "Epoch 234/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8609 - val_loss: 0.3375 - val_accuracy: 0.8585\n",
      "Epoch 235/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8567 - val_loss: 0.3361 - val_accuracy: 0.8635\n",
      "Epoch 236/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8600 - val_loss: 0.3361 - val_accuracy: 0.8580\n",
      "Epoch 237/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8572 - val_loss: 0.3347 - val_accuracy: 0.8600\n",
      "Epoch 238/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8583 - val_loss: 0.3344 - val_accuracy: 0.8605\n",
      "Epoch 239/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8574 - val_loss: 0.3360 - val_accuracy: 0.8605\n",
      "Epoch 240/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3499 - accuracy: 0.8559 - val_loss: 0.3373 - val_accuracy: 0.8615\n",
      "Epoch 241/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8644 - val_loss: 0.3401 - val_accuracy: 0.8625\n",
      "Epoch 242/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8555 - val_loss: 0.3380 - val_accuracy: 0.8575\n",
      "Epoch 243/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8613 - val_loss: 0.3475 - val_accuracy: 0.8595\n",
      "Epoch 244/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8637 - val_loss: 0.3370 - val_accuracy: 0.8575\n",
      "Epoch 245/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3469 - accuracy: 0.8558 - val_loss: 0.3351 - val_accuracy: 0.8620\n",
      "Epoch 246/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8566 - val_loss: 0.3362 - val_accuracy: 0.8595\n",
      "Epoch 247/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3499 - accuracy: 0.8562 - val_loss: 0.3430 - val_accuracy: 0.8590\n",
      "Epoch 248/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.8594 - val_loss: 0.3423 - val_accuracy: 0.8635\n",
      "Epoch 249/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8554 - val_loss: 0.3367 - val_accuracy: 0.8595\n",
      "Epoch 250/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8485 - val_loss: 0.3366 - val_accuracy: 0.8590\n",
      "Epoch 251/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3499 - accuracy: 0.8619 - val_loss: 0.3342 - val_accuracy: 0.8600\n",
      "Epoch 252/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8563 - val_loss: 0.3365 - val_accuracy: 0.8590\n",
      "Epoch 253/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8573 - val_loss: 0.3385 - val_accuracy: 0.8595\n",
      "Epoch 254/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8580 - val_loss: 0.3412 - val_accuracy: 0.8575\n",
      "Epoch 255/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8536 - val_loss: 0.3355 - val_accuracy: 0.8590\n",
      "Epoch 256/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8611 - val_loss: 0.3370 - val_accuracy: 0.8605\n",
      "Epoch 257/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8584 - val_loss: 0.3424 - val_accuracy: 0.8600\n",
      "Epoch 258/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3452 - accuracy: 0.8595 - val_loss: 0.3384 - val_accuracy: 0.8540\n",
      "Epoch 259/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8605 - val_loss: 0.3360 - val_accuracy: 0.8590\n",
      "Epoch 260/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3584 - accuracy: 0.8473 - val_loss: 0.3383 - val_accuracy: 0.8560\n",
      "Epoch 261/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8622 - val_loss: 0.3372 - val_accuracy: 0.8635\n",
      "Epoch 262/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8547 - val_loss: 0.3488 - val_accuracy: 0.8595\n",
      "Epoch 263/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8569 - val_loss: 0.3362 - val_accuracy: 0.8600\n",
      "Epoch 264/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3418 - accuracy: 0.8603 - val_loss: 0.3376 - val_accuracy: 0.8595\n",
      "Epoch 265/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8565 - val_loss: 0.3386 - val_accuracy: 0.8565\n",
      "Epoch 266/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3501 - accuracy: 0.8579 - val_loss: 0.3363 - val_accuracy: 0.8595\n",
      "Epoch 267/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8602 - val_loss: 0.3369 - val_accuracy: 0.8600\n",
      "Epoch 268/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3556 - accuracy: 0.8496 - val_loss: 0.3368 - val_accuracy: 0.8580\n",
      "Epoch 269/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8549 - val_loss: 0.3379 - val_accuracy: 0.8550\n",
      "Epoch 270/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8532 - val_loss: 0.3379 - val_accuracy: 0.8605\n",
      "Epoch 271/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8555 - val_loss: 0.3365 - val_accuracy: 0.8575\n",
      "Epoch 272/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8502 - val_loss: 0.3376 - val_accuracy: 0.8590\n",
      "Epoch 273/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8621 - val_loss: 0.3350 - val_accuracy: 0.8585\n",
      "Epoch 274/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8513 - val_loss: 0.3360 - val_accuracy: 0.8575\n",
      "Epoch 275/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3499 - accuracy: 0.8533 - val_loss: 0.3368 - val_accuracy: 0.8605\n",
      "Epoch 276/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3339 - accuracy: 0.8706 - val_loss: 0.3367 - val_accuracy: 0.8605\n",
      "Epoch 277/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3504 - accuracy: 0.8582 - val_loss: 0.3367 - val_accuracy: 0.8580\n",
      "Epoch 278/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8507 - val_loss: 0.3341 - val_accuracy: 0.8595\n",
      "Epoch 279/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8600 - val_loss: 0.3397 - val_accuracy: 0.8590\n",
      "Epoch 280/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8664 - val_loss: 0.3363 - val_accuracy: 0.8620\n",
      "Epoch 281/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8547 - val_loss: 0.3366 - val_accuracy: 0.8610\n",
      "Epoch 282/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8596 - val_loss: 0.3362 - val_accuracy: 0.8605\n",
      "Epoch 283/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8639 - val_loss: 0.3358 - val_accuracy: 0.8595\n",
      "Epoch 284/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8532 - val_loss: 0.3358 - val_accuracy: 0.8590\n",
      "Epoch 285/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8474 - val_loss: 0.3357 - val_accuracy: 0.8585\n",
      "Epoch 286/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8654 - val_loss: 0.3371 - val_accuracy: 0.8580\n",
      "Epoch 287/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8548 - val_loss: 0.3358 - val_accuracy: 0.8575\n",
      "Epoch 288/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8638 - val_loss: 0.3361 - val_accuracy: 0.8605\n",
      "Epoch 289/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8647 - val_loss: 0.3416 - val_accuracy: 0.8580\n",
      "Epoch 290/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8590 - val_loss: 0.3379 - val_accuracy: 0.8595\n",
      "Epoch 291/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8501 - val_loss: 0.3367 - val_accuracy: 0.8590\n",
      "Epoch 292/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3387 - accuracy: 0.8614 - val_loss: 0.3372 - val_accuracy: 0.8595\n",
      "Epoch 293/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8525 - val_loss: 0.3357 - val_accuracy: 0.8585\n",
      "Epoch 294/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8561 - val_loss: 0.3354 - val_accuracy: 0.8595\n",
      "Epoch 295/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8529 - val_loss: 0.3370 - val_accuracy: 0.8595\n",
      "Epoch 296/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8565 - val_loss: 0.3355 - val_accuracy: 0.8580\n",
      "Epoch 297/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8625 - val_loss: 0.3400 - val_accuracy: 0.8580\n",
      "Epoch 298/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8608 - val_loss: 0.3391 - val_accuracy: 0.8545\n",
      "Epoch 299/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8582 - val_loss: 0.3451 - val_accuracy: 0.8615\n",
      "Epoch 300/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8643 - val_loss: 0.3401 - val_accuracy: 0.8605\n",
      "Epoch 301/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8543 - val_loss: 0.3354 - val_accuracy: 0.8590\n",
      "Epoch 302/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8605 - val_loss: 0.3405 - val_accuracy: 0.8585\n",
      "Epoch 303/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8585 - val_loss: 0.3365 - val_accuracy: 0.8575\n",
      "Epoch 304/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8629 - val_loss: 0.3449 - val_accuracy: 0.8595\n",
      "Epoch 305/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8514 - val_loss: 0.3373 - val_accuracy: 0.8605\n",
      "Epoch 306/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8665 - val_loss: 0.3364 - val_accuracy: 0.8620\n",
      "Epoch 307/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3484 - accuracy: 0.8594 - val_loss: 0.3396 - val_accuracy: 0.8590\n",
      "Epoch 308/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8544 - val_loss: 0.3394 - val_accuracy: 0.8600\n",
      "Epoch 309/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8566 - val_loss: 0.3366 - val_accuracy: 0.8600\n",
      "Epoch 310/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8598 - val_loss: 0.3360 - val_accuracy: 0.8575\n",
      "Epoch 311/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8631 - val_loss: 0.3389 - val_accuracy: 0.8600\n",
      "Epoch 312/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8532 - val_loss: 0.3365 - val_accuracy: 0.8570\n",
      "Epoch 313/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8635 - val_loss: 0.3369 - val_accuracy: 0.8600\n",
      "Epoch 314/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8602 - val_loss: 0.3367 - val_accuracy: 0.8620\n",
      "Epoch 315/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8618 - val_loss: 0.3383 - val_accuracy: 0.8610\n",
      "Epoch 316/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8483 - val_loss: 0.3404 - val_accuracy: 0.8590\n",
      "Epoch 317/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8632 - val_loss: 0.3368 - val_accuracy: 0.8590\n",
      "Epoch 318/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8597 - val_loss: 0.3368 - val_accuracy: 0.8600\n",
      "Epoch 319/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8635 - val_loss: 0.3366 - val_accuracy: 0.8580\n",
      "Epoch 320/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3457 - accuracy: 0.8567 - val_loss: 0.3396 - val_accuracy: 0.8570\n",
      "Epoch 321/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8556 - val_loss: 0.3382 - val_accuracy: 0.8555\n",
      "Epoch 322/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8626 - val_loss: 0.3391 - val_accuracy: 0.8575\n",
      "Epoch 323/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8625 - val_loss: 0.3404 - val_accuracy: 0.8555\n",
      "Epoch 324/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8664 - val_loss: 0.3374 - val_accuracy: 0.8600\n",
      "Epoch 325/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8624 - val_loss: 0.3392 - val_accuracy: 0.8595\n",
      "Epoch 326/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8599 - val_loss: 0.3385 - val_accuracy: 0.8585\n",
      "Epoch 327/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.8582 - val_loss: 0.3367 - val_accuracy: 0.8590\n",
      "Epoch 328/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8551 - val_loss: 0.3360 - val_accuracy: 0.8600\n",
      "Epoch 329/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8568 - val_loss: 0.3425 - val_accuracy: 0.8530\n",
      "Epoch 330/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8609 - val_loss: 0.3374 - val_accuracy: 0.8595\n",
      "Epoch 331/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8594 - val_loss: 0.3431 - val_accuracy: 0.8605\n",
      "Epoch 332/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3391 - accuracy: 0.8624 - val_loss: 0.3407 - val_accuracy: 0.8555\n",
      "Epoch 333/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8549 - val_loss: 0.3354 - val_accuracy: 0.8625\n",
      "Epoch 334/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3419 - accuracy: 0.8621 - val_loss: 0.3415 - val_accuracy: 0.8585\n",
      "Epoch 335/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8604 - val_loss: 0.3362 - val_accuracy: 0.8585\n",
      "Epoch 336/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8576 - val_loss: 0.3402 - val_accuracy: 0.8560\n",
      "Epoch 337/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.8543 - val_loss: 0.3412 - val_accuracy: 0.8645\n",
      "Epoch 338/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8609 - val_loss: 0.3430 - val_accuracy: 0.8575\n",
      "Epoch 339/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8548 - val_loss: 0.3380 - val_accuracy: 0.8560\n",
      "Epoch 340/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8559 - val_loss: 0.3410 - val_accuracy: 0.8580\n",
      "Epoch 341/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8586 - val_loss: 0.3381 - val_accuracy: 0.8550\n",
      "Epoch 342/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8500 - val_loss: 0.3358 - val_accuracy: 0.8570\n",
      "Epoch 343/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8568 - val_loss: 0.3383 - val_accuracy: 0.8610\n",
      "Epoch 344/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8628 - val_loss: 0.3431 - val_accuracy: 0.8580\n",
      "Epoch 345/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8608 - val_loss: 0.3456 - val_accuracy: 0.8630\n",
      "Epoch 346/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8630 - val_loss: 0.3393 - val_accuracy: 0.8565\n",
      "Epoch 347/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3428 - accuracy: 0.8602 - val_loss: 0.3369 - val_accuracy: 0.8595\n",
      "Epoch 348/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8592 - val_loss: 0.3352 - val_accuracy: 0.8585\n",
      "Epoch 349/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8602 - val_loss: 0.3413 - val_accuracy: 0.8605\n",
      "Epoch 350/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3423 - accuracy: 0.8608 - val_loss: 0.3362 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2c1cfc1f60>"
      ]
     },
     "execution_count": 137,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train,y=y_train,epochs=350,validation_data=(x_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "St5Duyvqi65l"
   },
   "outputs": [],
   "source": [
    "model_loss=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "skpdsT7GjLsi",
    "outputId": "6eb61a6a-1734-4868-93cf-2442391203b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2c2332fe48>"
      ]
     },
     "execution_count": 140,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jp_M0mH7s8Wm"
   },
   "outputs": [],
   "source": [
    "# rmsprop\n",
    "model2=Sequential()\n",
    "model2.add(Dense(units=10,activation='relu'))\n",
    "model2.add(Dense(units=5,activation='relu'))\n",
    "model2.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5IXKVD3HtBPU",
    "outputId": "703343ea-0a47-431c-9a1f-ced20c49af16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5837 - accuracy: 0.7908 - val_loss: 0.4893 - val_accuracy: 0.8080\n",
      "Epoch 2/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5138 - accuracy: 0.7875 - val_loss: 0.4832 - val_accuracy: 0.8080\n",
      "Epoch 3/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.7918 - val_loss: 0.4770 - val_accuracy: 0.8080\n",
      "Epoch 4/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.7923 - val_loss: 0.4697 - val_accuracy: 0.8080\n",
      "Epoch 5/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4896 - accuracy: 0.7943 - val_loss: 0.4634 - val_accuracy: 0.8080\n",
      "Epoch 6/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7943 - val_loss: 0.4577 - val_accuracy: 0.8080\n",
      "Epoch 7/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7870 - val_loss: 0.4507 - val_accuracy: 0.8080\n",
      "Epoch 8/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7876 - val_loss: 0.4452 - val_accuracy: 0.8080\n",
      "Epoch 9/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7939 - val_loss: 0.4416 - val_accuracy: 0.8080\n",
      "Epoch 10/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7951 - val_loss: 0.4373 - val_accuracy: 0.8080\n",
      "Epoch 11/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.7843 - val_loss: 0.4334 - val_accuracy: 0.8080\n",
      "Epoch 12/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7951 - val_loss: 0.4315 - val_accuracy: 0.8075\n",
      "Epoch 13/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4267 - val_accuracy: 0.8065\n",
      "Epoch 14/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.8061 - val_loss: 0.4233 - val_accuracy: 0.8140\n",
      "Epoch 15/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7986 - val_loss: 0.4184 - val_accuracy: 0.8140\n",
      "Epoch 16/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8070 - val_loss: 0.4177 - val_accuracy: 0.8145\n",
      "Epoch 17/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4324 - accuracy: 0.8029 - val_loss: 0.4157 - val_accuracy: 0.8150\n",
      "Epoch 18/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.8017 - val_loss: 0.4089 - val_accuracy: 0.8125\n",
      "Epoch 19/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4297 - accuracy: 0.8039 - val_loss: 0.4058 - val_accuracy: 0.8140\n",
      "Epoch 20/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.8007 - val_loss: 0.4034 - val_accuracy: 0.8145\n",
      "Epoch 21/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.8035 - val_loss: 0.3999 - val_accuracy: 0.8175\n",
      "Epoch 22/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4190 - accuracy: 0.8067 - val_loss: 0.4015 - val_accuracy: 0.8265\n",
      "Epoch 23/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.7996 - val_loss: 0.3951 - val_accuracy: 0.8245\n",
      "Epoch 24/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4125 - accuracy: 0.8072 - val_loss: 0.3927 - val_accuracy: 0.8280\n",
      "Epoch 25/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.8048 - val_loss: 0.3905 - val_accuracy: 0.8265\n",
      "Epoch 26/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4206 - accuracy: 0.8105 - val_loss: 0.3878 - val_accuracy: 0.8220\n",
      "Epoch 27/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.8122 - val_loss: 0.3887 - val_accuracy: 0.8325\n",
      "Epoch 28/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.8137 - val_loss: 0.3872 - val_accuracy: 0.8310\n",
      "Epoch 29/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4026 - accuracy: 0.8205 - val_loss: 0.3818 - val_accuracy: 0.8330\n",
      "Epoch 30/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4090 - accuracy: 0.8139 - val_loss: 0.3812 - val_accuracy: 0.8365\n",
      "Epoch 31/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4027 - accuracy: 0.8242 - val_loss: 0.3785 - val_accuracy: 0.8390\n",
      "Epoch 32/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8253 - val_loss: 0.3777 - val_accuracy: 0.8430\n",
      "Epoch 33/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3957 - accuracy: 0.8253 - val_loss: 0.3760 - val_accuracy: 0.8415\n",
      "Epoch 34/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3993 - accuracy: 0.8218 - val_loss: 0.3754 - val_accuracy: 0.8420\n",
      "Epoch 35/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8227 - val_loss: 0.3749 - val_accuracy: 0.8435\n",
      "Epoch 36/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8216 - val_loss: 0.3752 - val_accuracy: 0.8425\n",
      "Epoch 37/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.8213 - val_loss: 0.3720 - val_accuracy: 0.8425\n",
      "Epoch 38/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8274 - val_loss: 0.3732 - val_accuracy: 0.8470\n",
      "Epoch 39/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3989 - accuracy: 0.8243 - val_loss: 0.3706 - val_accuracy: 0.8510\n",
      "Epoch 40/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8313 - val_loss: 0.3708 - val_accuracy: 0.8500\n",
      "Epoch 41/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3899 - accuracy: 0.8379 - val_loss: 0.3694 - val_accuracy: 0.8515\n",
      "Epoch 42/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3833 - accuracy: 0.8368 - val_loss: 0.3666 - val_accuracy: 0.8510\n",
      "Epoch 43/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3924 - accuracy: 0.8324 - val_loss: 0.3663 - val_accuracy: 0.8540\n",
      "Epoch 44/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4027 - accuracy: 0.8256 - val_loss: 0.3636 - val_accuracy: 0.8545\n",
      "Epoch 45/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8439 - val_loss: 0.3636 - val_accuracy: 0.8540\n",
      "Epoch 46/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8392 - val_loss: 0.3653 - val_accuracy: 0.8540\n",
      "Epoch 47/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8404 - val_loss: 0.3610 - val_accuracy: 0.8565\n",
      "Epoch 48/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8306 - val_loss: 0.3607 - val_accuracy: 0.8540\n",
      "Epoch 49/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8343 - val_loss: 0.3607 - val_accuracy: 0.8560\n",
      "Epoch 50/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3824 - accuracy: 0.8417 - val_loss: 0.3611 - val_accuracy: 0.8585\n",
      "Epoch 51/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.8429 - val_loss: 0.3571 - val_accuracy: 0.8585\n",
      "Epoch 52/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3761 - accuracy: 0.8444 - val_loss: 0.3566 - val_accuracy: 0.8600\n",
      "Epoch 53/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3758 - accuracy: 0.8467 - val_loss: 0.3556 - val_accuracy: 0.8585\n",
      "Epoch 54/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3910 - accuracy: 0.8459 - val_loss: 0.3548 - val_accuracy: 0.8595\n",
      "Epoch 55/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8403 - val_loss: 0.3537 - val_accuracy: 0.8625\n",
      "Epoch 56/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3744 - accuracy: 0.8483 - val_loss: 0.3538 - val_accuracy: 0.8615\n",
      "Epoch 57/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8513 - val_loss: 0.3558 - val_accuracy: 0.8635\n",
      "Epoch 58/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8486 - val_loss: 0.3522 - val_accuracy: 0.8635\n",
      "Epoch 59/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3779 - accuracy: 0.8460 - val_loss: 0.3514 - val_accuracy: 0.8645\n",
      "Epoch 60/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3771 - accuracy: 0.8460 - val_loss: 0.3513 - val_accuracy: 0.8625\n",
      "Epoch 61/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8484 - val_loss: 0.3496 - val_accuracy: 0.8630\n",
      "Epoch 62/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8468 - val_loss: 0.3541 - val_accuracy: 0.8575\n",
      "Epoch 63/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8525 - val_loss: 0.3507 - val_accuracy: 0.8665\n",
      "Epoch 64/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8482 - val_loss: 0.3487 - val_accuracy: 0.8635\n",
      "Epoch 65/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8474 - val_loss: 0.3477 - val_accuracy: 0.8650\n",
      "Epoch 66/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3576 - accuracy: 0.8573 - val_loss: 0.3507 - val_accuracy: 0.8655\n",
      "Epoch 67/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8489 - val_loss: 0.3477 - val_accuracy: 0.8645\n",
      "Epoch 68/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8503 - val_loss: 0.3471 - val_accuracy: 0.8650\n",
      "Epoch 69/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3675 - accuracy: 0.8557 - val_loss: 0.3499 - val_accuracy: 0.8660\n",
      "Epoch 70/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8544 - val_loss: 0.3493 - val_accuracy: 0.8665\n",
      "Epoch 71/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.8557 - val_loss: 0.3469 - val_accuracy: 0.8640\n",
      "Epoch 72/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3671 - accuracy: 0.8523 - val_loss: 0.3474 - val_accuracy: 0.8655\n",
      "Epoch 73/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8486 - val_loss: 0.3464 - val_accuracy: 0.8665\n",
      "Epoch 74/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.8490 - val_loss: 0.3461 - val_accuracy: 0.8660\n",
      "Epoch 75/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8540 - val_loss: 0.3456 - val_accuracy: 0.8640\n",
      "Epoch 76/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.8496 - val_loss: 0.3467 - val_accuracy: 0.8655\n",
      "Epoch 77/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3863 - accuracy: 0.8428 - val_loss: 0.3459 - val_accuracy: 0.8655\n",
      "Epoch 78/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8551 - val_loss: 0.3461 - val_accuracy: 0.8650\n",
      "Epoch 79/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8533 - val_loss: 0.3439 - val_accuracy: 0.8660\n",
      "Epoch 80/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3719 - accuracy: 0.8453 - val_loss: 0.3484 - val_accuracy: 0.8665\n",
      "Epoch 81/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3686 - accuracy: 0.8512 - val_loss: 0.3445 - val_accuracy: 0.8665\n",
      "Epoch 82/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3551 - accuracy: 0.8610 - val_loss: 0.3483 - val_accuracy: 0.8660\n",
      "Epoch 83/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8486 - val_loss: 0.3467 - val_accuracy: 0.8675\n",
      "Epoch 84/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8504 - val_loss: 0.3444 - val_accuracy: 0.8665\n",
      "Epoch 85/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8517 - val_loss: 0.3461 - val_accuracy: 0.8665\n",
      "Epoch 86/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8510 - val_loss: 0.3448 - val_accuracy: 0.8655\n",
      "Epoch 87/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3670 - accuracy: 0.8504 - val_loss: 0.3469 - val_accuracy: 0.8675\n",
      "Epoch 88/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3706 - accuracy: 0.8472 - val_loss: 0.3438 - val_accuracy: 0.8670\n",
      "Epoch 89/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3677 - accuracy: 0.8517 - val_loss: 0.3475 - val_accuracy: 0.8605\n",
      "Epoch 90/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8551 - val_loss: 0.3430 - val_accuracy: 0.8655\n",
      "Epoch 91/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3706 - accuracy: 0.8475 - val_loss: 0.3442 - val_accuracy: 0.8655\n",
      "Epoch 92/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3662 - accuracy: 0.8518 - val_loss: 0.3425 - val_accuracy: 0.8685\n",
      "Epoch 93/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8639 - val_loss: 0.3432 - val_accuracy: 0.8660\n",
      "Epoch 94/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8535 - val_loss: 0.3444 - val_accuracy: 0.8680\n",
      "Epoch 95/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8479 - val_loss: 0.3465 - val_accuracy: 0.8650\n",
      "Epoch 96/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3677 - accuracy: 0.8510 - val_loss: 0.3434 - val_accuracy: 0.8680\n",
      "Epoch 97/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8531 - val_loss: 0.3444 - val_accuracy: 0.8650\n",
      "Epoch 98/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8515 - val_loss: 0.3442 - val_accuracy: 0.8665\n",
      "Epoch 99/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8519 - val_loss: 0.3420 - val_accuracy: 0.8680\n",
      "Epoch 100/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8478 - val_loss: 0.3416 - val_accuracy: 0.8675\n",
      "Epoch 101/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8553 - val_loss: 0.3423 - val_accuracy: 0.8680\n",
      "Epoch 102/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8580 - val_loss: 0.3441 - val_accuracy: 0.8665\n",
      "Epoch 103/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8515 - val_loss: 0.3433 - val_accuracy: 0.8670\n",
      "Epoch 104/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8528 - val_loss: 0.3418 - val_accuracy: 0.8680\n",
      "Epoch 105/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8514 - val_loss: 0.3416 - val_accuracy: 0.8680\n",
      "Epoch 106/350\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3529 - accuracy: 0.8587 - val_loss: 0.3426 - val_accuracy: 0.8665\n",
      "Epoch 107/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8520 - val_loss: 0.3411 - val_accuracy: 0.8670\n",
      "Epoch 108/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8482 - val_loss: 0.3425 - val_accuracy: 0.8655\n",
      "Epoch 109/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3679 - accuracy: 0.8511 - val_loss: 0.3424 - val_accuracy: 0.8665\n",
      "Epoch 110/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8529 - val_loss: 0.3433 - val_accuracy: 0.8665\n",
      "Epoch 111/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8583 - val_loss: 0.3426 - val_accuracy: 0.8665\n",
      "Epoch 112/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8565 - val_loss: 0.3406 - val_accuracy: 0.8670\n",
      "Epoch 113/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8489 - val_loss: 0.3422 - val_accuracy: 0.8675\n",
      "Epoch 114/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8518 - val_loss: 0.3418 - val_accuracy: 0.8675\n",
      "Epoch 115/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8550 - val_loss: 0.3417 - val_accuracy: 0.8670\n",
      "Epoch 116/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8563 - val_loss: 0.3450 - val_accuracy: 0.8660\n",
      "Epoch 117/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8590 - val_loss: 0.3413 - val_accuracy: 0.8665\n",
      "Epoch 118/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8554 - val_loss: 0.3408 - val_accuracy: 0.8680\n",
      "Epoch 119/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8530 - val_loss: 0.3403 - val_accuracy: 0.8665\n",
      "Epoch 120/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8579 - val_loss: 0.3418 - val_accuracy: 0.8650\n",
      "Epoch 121/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3519 - accuracy: 0.8629 - val_loss: 0.3415 - val_accuracy: 0.8695\n",
      "Epoch 122/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3548 - accuracy: 0.8537 - val_loss: 0.3428 - val_accuracy: 0.8670\n",
      "Epoch 123/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8581 - val_loss: 0.3441 - val_accuracy: 0.8655\n",
      "Epoch 124/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8558 - val_loss: 0.3411 - val_accuracy: 0.8660\n",
      "Epoch 125/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8532 - val_loss: 0.3412 - val_accuracy: 0.8680\n",
      "Epoch 126/350\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3586 - accuracy: 0.8558 - val_loss: 0.3408 - val_accuracy: 0.8670\n",
      "Epoch 127/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8575 - val_loss: 0.3423 - val_accuracy: 0.8675\n",
      "Epoch 128/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8515 - val_loss: 0.3430 - val_accuracy: 0.8665\n",
      "Epoch 129/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8469 - val_loss: 0.3407 - val_accuracy: 0.8665\n",
      "Epoch 130/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8492 - val_loss: 0.3412 - val_accuracy: 0.8675\n",
      "Epoch 131/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3628 - accuracy: 0.8502 - val_loss: 0.3411 - val_accuracy: 0.8670\n",
      "Epoch 132/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8525 - val_loss: 0.3418 - val_accuracy: 0.8650\n",
      "Epoch 133/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8509 - val_loss: 0.3414 - val_accuracy: 0.8665\n",
      "Epoch 134/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8552 - val_loss: 0.3458 - val_accuracy: 0.8655\n",
      "Epoch 135/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8573 - val_loss: 0.3405 - val_accuracy: 0.8660\n",
      "Epoch 136/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8504 - val_loss: 0.3416 - val_accuracy: 0.8665\n",
      "Epoch 137/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8502 - val_loss: 0.3437 - val_accuracy: 0.8645\n",
      "Epoch 138/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3645 - accuracy: 0.8494 - val_loss: 0.3407 - val_accuracy: 0.8660\n",
      "Epoch 139/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8570 - val_loss: 0.3407 - val_accuracy: 0.8680\n",
      "Epoch 140/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3584 - accuracy: 0.8512 - val_loss: 0.3419 - val_accuracy: 0.8665\n",
      "Epoch 141/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8575 - val_loss: 0.3432 - val_accuracy: 0.8670\n",
      "Epoch 142/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8493 - val_loss: 0.3403 - val_accuracy: 0.8660\n",
      "Epoch 143/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8484 - val_loss: 0.3417 - val_accuracy: 0.8665\n",
      "Epoch 144/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8544 - val_loss: 0.3398 - val_accuracy: 0.8650\n",
      "Epoch 145/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8537 - val_loss: 0.3403 - val_accuracy: 0.8675\n",
      "Epoch 146/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8512 - val_loss: 0.3410 - val_accuracy: 0.8675\n",
      "Epoch 147/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8511 - val_loss: 0.3412 - val_accuracy: 0.8655\n",
      "Epoch 148/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.8504 - val_loss: 0.3427 - val_accuracy: 0.8660\n",
      "Epoch 149/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8530 - val_loss: 0.3398 - val_accuracy: 0.8680\n",
      "Epoch 150/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8522 - val_loss: 0.3407 - val_accuracy: 0.8670\n",
      "Epoch 151/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8540 - val_loss: 0.3412 - val_accuracy: 0.8675\n",
      "Epoch 152/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8521 - val_loss: 0.3433 - val_accuracy: 0.8655\n",
      "Epoch 153/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8529 - val_loss: 0.3402 - val_accuracy: 0.8665\n",
      "Epoch 154/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8433 - val_loss: 0.3438 - val_accuracy: 0.8665\n",
      "Epoch 155/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8583 - val_loss: 0.3434 - val_accuracy: 0.8670\n",
      "Epoch 156/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3653 - accuracy: 0.8467 - val_loss: 0.3437 - val_accuracy: 0.8650\n",
      "Epoch 157/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8504 - val_loss: 0.3415 - val_accuracy: 0.8665\n",
      "Epoch 158/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8533 - val_loss: 0.3400 - val_accuracy: 0.8670\n",
      "Epoch 159/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8607 - val_loss: 0.3430 - val_accuracy: 0.8645\n",
      "Epoch 160/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8515 - val_loss: 0.3442 - val_accuracy: 0.8655\n",
      "Epoch 161/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8520 - val_loss: 0.3422 - val_accuracy: 0.8665\n",
      "Epoch 162/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.8555 - val_loss: 0.3409 - val_accuracy: 0.8665\n",
      "Epoch 163/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8532 - val_loss: 0.3413 - val_accuracy: 0.8670\n",
      "Epoch 164/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8560 - val_loss: 0.3412 - val_accuracy: 0.8660\n",
      "Epoch 165/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8519 - val_loss: 0.3407 - val_accuracy: 0.8655\n",
      "Epoch 166/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8562 - val_loss: 0.3405 - val_accuracy: 0.8670\n",
      "Epoch 167/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8531 - val_loss: 0.3402 - val_accuracy: 0.8675\n",
      "Epoch 168/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8518 - val_loss: 0.3416 - val_accuracy: 0.8675\n",
      "Epoch 169/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8558 - val_loss: 0.3421 - val_accuracy: 0.8670\n",
      "Epoch 170/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8547 - val_loss: 0.3432 - val_accuracy: 0.8630\n",
      "Epoch 171/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3473 - accuracy: 0.8599 - val_loss: 0.3405 - val_accuracy: 0.8685\n",
      "Epoch 172/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3534 - accuracy: 0.8590 - val_loss: 0.3469 - val_accuracy: 0.8645\n",
      "Epoch 173/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8531 - val_loss: 0.3400 - val_accuracy: 0.8645\n",
      "Epoch 174/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8445 - val_loss: 0.3422 - val_accuracy: 0.8675\n",
      "Epoch 175/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8590 - val_loss: 0.3401 - val_accuracy: 0.8685\n",
      "Epoch 176/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8463 - val_loss: 0.3412 - val_accuracy: 0.8685\n",
      "Epoch 177/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8598 - val_loss: 0.3416 - val_accuracy: 0.8655\n",
      "Epoch 178/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3564 - accuracy: 0.8524 - val_loss: 0.3438 - val_accuracy: 0.8650\n",
      "Epoch 179/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8488 - val_loss: 0.3421 - val_accuracy: 0.8635\n",
      "Epoch 180/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8474 - val_loss: 0.3445 - val_accuracy: 0.8665\n",
      "Epoch 181/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8527 - val_loss: 0.3416 - val_accuracy: 0.8650\n",
      "Epoch 182/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3543 - accuracy: 0.8537 - val_loss: 0.3410 - val_accuracy: 0.8675\n",
      "Epoch 183/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8532 - val_loss: 0.3404 - val_accuracy: 0.8685\n",
      "Epoch 184/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3504 - accuracy: 0.8593 - val_loss: 0.3539 - val_accuracy: 0.8590\n",
      "Epoch 185/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8498 - val_loss: 0.3405 - val_accuracy: 0.8660\n",
      "Epoch 186/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8584 - val_loss: 0.3416 - val_accuracy: 0.8665\n",
      "Epoch 187/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8578 - val_loss: 0.3398 - val_accuracy: 0.8660\n",
      "Epoch 188/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8485 - val_loss: 0.3393 - val_accuracy: 0.8670\n",
      "Epoch 189/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8534 - val_loss: 0.3427 - val_accuracy: 0.8650\n",
      "Epoch 190/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8566 - val_loss: 0.3462 - val_accuracy: 0.8635\n",
      "Epoch 191/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8542 - val_loss: 0.3436 - val_accuracy: 0.8650\n",
      "Epoch 192/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8545 - val_loss: 0.3414 - val_accuracy: 0.8635\n",
      "Epoch 193/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8499 - val_loss: 0.3402 - val_accuracy: 0.8655\n",
      "Epoch 194/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8457 - val_loss: 0.3399 - val_accuracy: 0.8660\n",
      "Epoch 195/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8548 - val_loss: 0.3417 - val_accuracy: 0.8645\n",
      "Epoch 196/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8482 - val_loss: 0.3429 - val_accuracy: 0.8645\n",
      "Epoch 197/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8576 - val_loss: 0.3420 - val_accuracy: 0.8670\n",
      "Epoch 198/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3621 - accuracy: 0.8552 - val_loss: 0.3417 - val_accuracy: 0.8655\n",
      "Epoch 199/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8541 - val_loss: 0.3421 - val_accuracy: 0.8660\n",
      "Epoch 200/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8550 - val_loss: 0.3400 - val_accuracy: 0.8655\n",
      "Epoch 201/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8557 - val_loss: 0.3398 - val_accuracy: 0.8665\n",
      "Epoch 202/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8510 - val_loss: 0.3427 - val_accuracy: 0.8640\n",
      "Epoch 203/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8523 - val_loss: 0.3390 - val_accuracy: 0.8680\n",
      "Epoch 204/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8506 - val_loss: 0.3424 - val_accuracy: 0.8650\n",
      "Epoch 205/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8548 - val_loss: 0.3400 - val_accuracy: 0.8675\n",
      "Epoch 206/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8419 - val_loss: 0.3407 - val_accuracy: 0.8655\n",
      "Epoch 207/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8572 - val_loss: 0.3398 - val_accuracy: 0.8660\n",
      "Epoch 208/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8537 - val_loss: 0.3434 - val_accuracy: 0.8640\n",
      "Epoch 209/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8533 - val_loss: 0.3395 - val_accuracy: 0.8655\n",
      "Epoch 210/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8485 - val_loss: 0.3403 - val_accuracy: 0.8660\n",
      "Epoch 211/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8489 - val_loss: 0.3393 - val_accuracy: 0.8680\n",
      "Epoch 212/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8599 - val_loss: 0.3406 - val_accuracy: 0.8660\n",
      "Epoch 213/350\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8513 - val_loss: 0.3400 - val_accuracy: 0.8650\n",
      "Epoch 214/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8553 - val_loss: 0.3398 - val_accuracy: 0.8660\n",
      "Epoch 215/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.8514 - val_loss: 0.3398 - val_accuracy: 0.8670\n",
      "Epoch 216/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8526 - val_loss: 0.3409 - val_accuracy: 0.8650\n",
      "Epoch 217/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8594 - val_loss: 0.3422 - val_accuracy: 0.8655\n",
      "Epoch 218/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8649 - val_loss: 0.3409 - val_accuracy: 0.8645\n",
      "Epoch 219/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3583 - accuracy: 0.8569 - val_loss: 0.3407 - val_accuracy: 0.8670\n",
      "Epoch 220/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3512 - accuracy: 0.8558 - val_loss: 0.3396 - val_accuracy: 0.8645\n",
      "Epoch 221/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8494 - val_loss: 0.3396 - val_accuracy: 0.8670\n",
      "Epoch 222/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8528 - val_loss: 0.3441 - val_accuracy: 0.8635\n",
      "Epoch 223/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8525 - val_loss: 0.3432 - val_accuracy: 0.8645\n",
      "Epoch 224/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8553 - val_loss: 0.3393 - val_accuracy: 0.8650\n",
      "Epoch 225/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8464 - val_loss: 0.3411 - val_accuracy: 0.8640\n",
      "Epoch 226/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8508 - val_loss: 0.3406 - val_accuracy: 0.8650\n",
      "Epoch 227/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8530 - val_loss: 0.3491 - val_accuracy: 0.8630\n",
      "Epoch 228/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8507 - val_loss: 0.3417 - val_accuracy: 0.8655\n",
      "Epoch 229/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8533 - val_loss: 0.3407 - val_accuracy: 0.8660\n",
      "Epoch 230/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8573 - val_loss: 0.3398 - val_accuracy: 0.8655\n",
      "Epoch 231/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8524 - val_loss: 0.3408 - val_accuracy: 0.8655\n",
      "Epoch 232/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8537 - val_loss: 0.3405 - val_accuracy: 0.8655\n",
      "Epoch 233/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8495 - val_loss: 0.3405 - val_accuracy: 0.8650\n",
      "Epoch 234/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8421 - val_loss: 0.3395 - val_accuracy: 0.8660\n",
      "Epoch 235/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8571 - val_loss: 0.3397 - val_accuracy: 0.8660\n",
      "Epoch 236/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8451 - val_loss: 0.3406 - val_accuracy: 0.8665\n",
      "Epoch 237/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8555 - val_loss: 0.3414 - val_accuracy: 0.8650\n",
      "Epoch 238/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8527 - val_loss: 0.3400 - val_accuracy: 0.8655\n",
      "Epoch 239/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8558 - val_loss: 0.3431 - val_accuracy: 0.8640\n",
      "Epoch 240/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8514 - val_loss: 0.3416 - val_accuracy: 0.8645\n",
      "Epoch 241/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8567 - val_loss: 0.3396 - val_accuracy: 0.8655\n",
      "Epoch 242/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8537 - val_loss: 0.3404 - val_accuracy: 0.8645\n",
      "Epoch 243/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8502 - val_loss: 0.3396 - val_accuracy: 0.8655\n",
      "Epoch 244/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8581 - val_loss: 0.3462 - val_accuracy: 0.8625\n",
      "Epoch 245/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8565 - val_loss: 0.3408 - val_accuracy: 0.8640\n",
      "Epoch 246/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8514 - val_loss: 0.3398 - val_accuracy: 0.8665\n",
      "Epoch 247/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8542 - val_loss: 0.3402 - val_accuracy: 0.8660\n",
      "Epoch 248/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8550 - val_loss: 0.3389 - val_accuracy: 0.8660\n",
      "Epoch 249/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8614 - val_loss: 0.3405 - val_accuracy: 0.8655\n",
      "Epoch 250/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8503 - val_loss: 0.3512 - val_accuracy: 0.8590\n",
      "Epoch 251/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8518 - val_loss: 0.3397 - val_accuracy: 0.8660\n",
      "Epoch 252/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8500 - val_loss: 0.3448 - val_accuracy: 0.8635\n",
      "Epoch 253/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8563 - val_loss: 0.3423 - val_accuracy: 0.8650\n",
      "Epoch 254/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8518 - val_loss: 0.3388 - val_accuracy: 0.8660\n",
      "Epoch 255/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8632 - val_loss: 0.3389 - val_accuracy: 0.8670\n",
      "Epoch 256/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8567 - val_loss: 0.3407 - val_accuracy: 0.8655\n",
      "Epoch 257/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8469 - val_loss: 0.3436 - val_accuracy: 0.8630\n",
      "Epoch 258/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8482 - val_loss: 0.3388 - val_accuracy: 0.8670\n",
      "Epoch 259/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8582 - val_loss: 0.3388 - val_accuracy: 0.8660\n",
      "Epoch 260/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3662 - accuracy: 0.8496 - val_loss: 0.3393 - val_accuracy: 0.8660\n",
      "Epoch 261/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8509 - val_loss: 0.3400 - val_accuracy: 0.8650\n",
      "Epoch 262/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8487 - val_loss: 0.3417 - val_accuracy: 0.8655\n",
      "Epoch 263/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8529 - val_loss: 0.3401 - val_accuracy: 0.8650\n",
      "Epoch 264/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3578 - accuracy: 0.8528 - val_loss: 0.3398 - val_accuracy: 0.8665\n",
      "Epoch 265/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3513 - accuracy: 0.8580 - val_loss: 0.3394 - val_accuracy: 0.8660\n",
      "Epoch 266/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8527 - val_loss: 0.3413 - val_accuracy: 0.8650\n",
      "Epoch 267/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8538 - val_loss: 0.3390 - val_accuracy: 0.8675\n",
      "Epoch 268/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3627 - accuracy: 0.8507 - val_loss: 0.3406 - val_accuracy: 0.8650\n",
      "Epoch 269/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8537 - val_loss: 0.3422 - val_accuracy: 0.8660\n",
      "Epoch 270/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8494 - val_loss: 0.3395 - val_accuracy: 0.8660\n",
      "Epoch 271/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8501 - val_loss: 0.3415 - val_accuracy: 0.8650\n",
      "Epoch 272/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8538 - val_loss: 0.3396 - val_accuracy: 0.8660\n",
      "Epoch 273/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8512 - val_loss: 0.3410 - val_accuracy: 0.8645\n",
      "Epoch 274/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3503 - accuracy: 0.8566 - val_loss: 0.3421 - val_accuracy: 0.8635\n",
      "Epoch 275/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8582 - val_loss: 0.3410 - val_accuracy: 0.8670\n",
      "Epoch 276/350\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3648 - accuracy: 0.8441 - val_loss: 0.3395 - val_accuracy: 0.8670\n",
      "Epoch 277/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8567 - val_loss: 0.3412 - val_accuracy: 0.8645\n",
      "Epoch 278/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8500 - val_loss: 0.3402 - val_accuracy: 0.8640\n",
      "Epoch 279/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8575 - val_loss: 0.3450 - val_accuracy: 0.8635\n",
      "Epoch 280/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8624 - val_loss: 0.3416 - val_accuracy: 0.8655\n",
      "Epoch 281/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8557 - val_loss: 0.3387 - val_accuracy: 0.8665\n",
      "Epoch 282/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8511 - val_loss: 0.3417 - val_accuracy: 0.8650\n",
      "Epoch 283/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8541 - val_loss: 0.3408 - val_accuracy: 0.8660\n",
      "Epoch 284/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8563 - val_loss: 0.3414 - val_accuracy: 0.8655\n",
      "Epoch 285/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8540 - val_loss: 0.3389 - val_accuracy: 0.8665\n",
      "Epoch 286/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8418 - val_loss: 0.3402 - val_accuracy: 0.8655\n",
      "Epoch 287/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8554 - val_loss: 0.3396 - val_accuracy: 0.8660\n",
      "Epoch 288/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8538 - val_loss: 0.3467 - val_accuracy: 0.8635\n",
      "Epoch 289/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8547 - val_loss: 0.3391 - val_accuracy: 0.8670\n",
      "Epoch 290/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8543 - val_loss: 0.3395 - val_accuracy: 0.8675\n",
      "Epoch 291/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8517 - val_loss: 0.3404 - val_accuracy: 0.8670\n",
      "Epoch 292/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8591 - val_loss: 0.3384 - val_accuracy: 0.8655\n",
      "Epoch 293/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8465 - val_loss: 0.3426 - val_accuracy: 0.8650\n",
      "Epoch 294/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8571 - val_loss: 0.3418 - val_accuracy: 0.8645\n",
      "Epoch 295/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8531 - val_loss: 0.3398 - val_accuracy: 0.8675\n",
      "Epoch 296/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8518 - val_loss: 0.3383 - val_accuracy: 0.8655\n",
      "Epoch 297/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8535 - val_loss: 0.3389 - val_accuracy: 0.8665\n",
      "Epoch 298/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8599 - val_loss: 0.3390 - val_accuracy: 0.8665\n",
      "Epoch 299/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8552 - val_loss: 0.3412 - val_accuracy: 0.8655\n",
      "Epoch 300/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8568 - val_loss: 0.3395 - val_accuracy: 0.8660\n",
      "Epoch 301/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8509 - val_loss: 0.3386 - val_accuracy: 0.8670\n",
      "Epoch 302/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8491 - val_loss: 0.3403 - val_accuracy: 0.8650\n",
      "Epoch 303/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8531 - val_loss: 0.3393 - val_accuracy: 0.8650\n",
      "Epoch 304/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8565 - val_loss: 0.3401 - val_accuracy: 0.8665\n",
      "Epoch 305/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8533 - val_loss: 0.3408 - val_accuracy: 0.8660\n",
      "Epoch 306/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3612 - accuracy: 0.8507 - val_loss: 0.3400 - val_accuracy: 0.8665\n",
      "Epoch 307/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8562 - val_loss: 0.3392 - val_accuracy: 0.8665\n",
      "Epoch 308/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8569 - val_loss: 0.3382 - val_accuracy: 0.8660\n",
      "Epoch 309/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8470 - val_loss: 0.3384 - val_accuracy: 0.8670\n",
      "Epoch 310/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8511 - val_loss: 0.3407 - val_accuracy: 0.8670\n",
      "Epoch 311/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8534 - val_loss: 0.3389 - val_accuracy: 0.8655\n",
      "Epoch 312/350\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3560 - accuracy: 0.8510 - val_loss: 0.3415 - val_accuracy: 0.8630\n",
      "Epoch 313/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8512 - val_loss: 0.3387 - val_accuracy: 0.8655\n",
      "Epoch 314/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8487 - val_loss: 0.3388 - val_accuracy: 0.8675\n",
      "Epoch 315/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8527 - val_loss: 0.3430 - val_accuracy: 0.8650\n",
      "Epoch 316/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8486 - val_loss: 0.3423 - val_accuracy: 0.8645\n",
      "Epoch 317/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8522 - val_loss: 0.3452 - val_accuracy: 0.8645\n",
      "Epoch 318/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8550 - val_loss: 0.3453 - val_accuracy: 0.8645\n",
      "Epoch 319/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8527 - val_loss: 0.3391 - val_accuracy: 0.8665\n",
      "Epoch 320/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8531 - val_loss: 0.3421 - val_accuracy: 0.8665\n",
      "Epoch 321/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8574 - val_loss: 0.3469 - val_accuracy: 0.8625\n",
      "Epoch 322/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8532 - val_loss: 0.3408 - val_accuracy: 0.8655\n",
      "Epoch 323/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8536 - val_loss: 0.3394 - val_accuracy: 0.8660\n",
      "Epoch 324/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.8453 - val_loss: 0.3383 - val_accuracy: 0.8655\n",
      "Epoch 325/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8450 - val_loss: 0.3392 - val_accuracy: 0.8635\n",
      "Epoch 326/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8543 - val_loss: 0.3388 - val_accuracy: 0.8665\n",
      "Epoch 327/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8526 - val_loss: 0.3431 - val_accuracy: 0.8635\n",
      "Epoch 328/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8543 - val_loss: 0.3384 - val_accuracy: 0.8675\n",
      "Epoch 329/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8475 - val_loss: 0.3556 - val_accuracy: 0.8555\n",
      "Epoch 330/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8584 - val_loss: 0.3403 - val_accuracy: 0.8645\n",
      "Epoch 331/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8596 - val_loss: 0.3401 - val_accuracy: 0.8660\n",
      "Epoch 332/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8541 - val_loss: 0.3394 - val_accuracy: 0.8655\n",
      "Epoch 333/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8537 - val_loss: 0.3461 - val_accuracy: 0.8635\n",
      "Epoch 334/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.8582 - val_loss: 0.3399 - val_accuracy: 0.8640\n",
      "Epoch 335/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8550 - val_loss: 0.3387 - val_accuracy: 0.8635\n",
      "Epoch 336/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8484 - val_loss: 0.3404 - val_accuracy: 0.8665\n",
      "Epoch 337/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3548 - accuracy: 0.8514 - val_loss: 0.3405 - val_accuracy: 0.8655\n",
      "Epoch 338/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8534 - val_loss: 0.3398 - val_accuracy: 0.8660\n",
      "Epoch 339/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8559 - val_loss: 0.3385 - val_accuracy: 0.8680\n",
      "Epoch 340/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8506 - val_loss: 0.3447 - val_accuracy: 0.8650\n",
      "Epoch 341/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8534 - val_loss: 0.3376 - val_accuracy: 0.8665\n",
      "Epoch 342/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8560 - val_loss: 0.3386 - val_accuracy: 0.8665\n",
      "Epoch 343/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8552 - val_loss: 0.3426 - val_accuracy: 0.8645\n",
      "Epoch 344/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8452 - val_loss: 0.3399 - val_accuracy: 0.8650\n",
      "Epoch 345/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8581 - val_loss: 0.3396 - val_accuracy: 0.8660\n",
      "Epoch 346/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8575 - val_loss: 0.3402 - val_accuracy: 0.8665\n",
      "Epoch 347/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3523 - accuracy: 0.8543 - val_loss: 0.3388 - val_accuracy: 0.8670\n",
      "Epoch 348/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8535 - val_loss: 0.3414 - val_accuracy: 0.8650\n",
      "Epoch 349/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3659 - accuracy: 0.8476 - val_loss: 0.3396 - val_accuracy: 0.8670\n",
      "Epoch 350/350\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8514 - val_loss: 0.3391 - val_accuracy: 0.8670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2c1a53b6d8>"
      ]
     },
     "execution_count": 129,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x=x_train,y=y_train,epochs=350,validation_data=(x_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tk9tXmt2j2La"
   },
   "outputs": [],
   "source": [
    "#Adding Dropout Layers\n",
    "\n",
    "model3=Sequential()\n",
    "model3.add(Dense(units=10,activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "\n",
    "model3.add(Dense(units=5,activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "\n",
    "model3.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "model3.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zrlbI_ImRJW",
    "outputId": "56b34da9-1c6e-4b14-b9c0-0338dd909ae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5962 - accuracy: 0.7837 - val_loss: 0.4935 - val_accuracy: 0.8080\n",
      "Epoch 2/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7922 - val_loss: 0.4862 - val_accuracy: 0.8080\n",
      "Epoch 3/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.8020 - val_loss: 0.4802 - val_accuracy: 0.8080\n",
      "Epoch 4/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7927 - val_loss: 0.4728 - val_accuracy: 0.8080\n",
      "Epoch 5/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7969 - val_loss: 0.4730 - val_accuracy: 0.8080\n",
      "Epoch 6/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7926 - val_loss: 0.4684 - val_accuracy: 0.8080\n",
      "Epoch 7/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7860 - val_loss: 0.4610 - val_accuracy: 0.8080\n",
      "Epoch 8/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7912 - val_loss: 0.4623 - val_accuracy: 0.8080\n",
      "Epoch 9/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7966 - val_loss: 0.4547 - val_accuracy: 0.8080\n",
      "Epoch 10/300\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.7861 - val_loss: 0.4562 - val_accuracy: 0.8080\n",
      "Epoch 11/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7921 - val_loss: 0.4528 - val_accuracy: 0.8080\n",
      "Epoch 12/300\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7966 - val_loss: 0.4528 - val_accuracy: 0.8080\n",
      "Epoch 13/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7875 - val_loss: 0.4493 - val_accuracy: 0.8080\n",
      "Epoch 14/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7930 - val_loss: 0.4466 - val_accuracy: 0.8080\n",
      "Epoch 15/300\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4798 - accuracy: 0.7988 - val_loss: 0.4443 - val_accuracy: 0.8080\n",
      "Epoch 16/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7967 - val_loss: 0.4410 - val_accuracy: 0.8080\n",
      "Epoch 17/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7843 - val_loss: 0.4417 - val_accuracy: 0.8080\n",
      "Epoch 18/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7958 - val_loss: 0.4410 - val_accuracy: 0.8080\n",
      "Epoch 19/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7956 - val_loss: 0.4423 - val_accuracy: 0.8080\n",
      "Epoch 20/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7880 - val_loss: 0.4394 - val_accuracy: 0.8080\n",
      "Epoch 21/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7970 - val_loss: 0.4365 - val_accuracy: 0.8080\n",
      "Epoch 22/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7917 - val_loss: 0.4340 - val_accuracy: 0.8080\n",
      "Epoch 23/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7902 - val_loss: 0.4372 - val_accuracy: 0.8080\n",
      "Epoch 24/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8100 - val_loss: 0.4374 - val_accuracy: 0.8080\n",
      "Epoch 25/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.8014 - val_loss: 0.4354 - val_accuracy: 0.8080\n",
      "Epoch 26/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7972 - val_loss: 0.4340 - val_accuracy: 0.8080\n",
      "Epoch 27/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7971 - val_loss: 0.4309 - val_accuracy: 0.8080\n",
      "Epoch 28/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7992 - val_loss: 0.4324 - val_accuracy: 0.8080\n",
      "Epoch 29/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7947 - val_loss: 0.4314 - val_accuracy: 0.8080\n",
      "Epoch 30/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7962 - val_loss: 0.4289 - val_accuracy: 0.8080\n",
      "Epoch 31/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.8065 - val_loss: 0.4282 - val_accuracy: 0.8080\n",
      "Epoch 32/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.8049 - val_loss: 0.4285 - val_accuracy: 0.8080\n",
      "Epoch 33/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7988 - val_loss: 0.4268 - val_accuracy: 0.8080\n",
      "Epoch 34/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7945 - val_loss: 0.4280 - val_accuracy: 0.8075\n",
      "Epoch 35/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7884 - val_loss: 0.4245 - val_accuracy: 0.8080\n",
      "Epoch 36/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7987 - val_loss: 0.4284 - val_accuracy: 0.8065\n",
      "Epoch 37/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.8003 - val_loss: 0.4254 - val_accuracy: 0.8065\n",
      "Epoch 38/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8061 - val_loss: 0.4278 - val_accuracy: 0.8080\n",
      "Epoch 39/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7978 - val_loss: 0.4214 - val_accuracy: 0.8070\n",
      "Epoch 40/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7971 - val_loss: 0.4173 - val_accuracy: 0.8075\n",
      "Epoch 41/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.8066 - val_loss: 0.4245 - val_accuracy: 0.8070\n",
      "Epoch 42/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.8033 - val_loss: 0.4175 - val_accuracy: 0.8085\n",
      "Epoch 43/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8007 - val_loss: 0.4188 - val_accuracy: 0.8085\n",
      "Epoch 44/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7998 - val_loss: 0.4170 - val_accuracy: 0.8075\n",
      "Epoch 45/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.8043 - val_loss: 0.4162 - val_accuracy: 0.8090\n",
      "Epoch 46/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8128 - val_loss: 0.4166 - val_accuracy: 0.8085\n",
      "Epoch 47/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.8009 - val_loss: 0.4209 - val_accuracy: 0.8075\n",
      "Epoch 48/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.8051 - val_loss: 0.4158 - val_accuracy: 0.8085\n",
      "Epoch 49/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.8056 - val_loss: 0.4157 - val_accuracy: 0.8095\n",
      "Epoch 50/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.8030 - val_loss: 0.4174 - val_accuracy: 0.8085\n",
      "Epoch 51/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8076 - val_loss: 0.4152 - val_accuracy: 0.8110\n",
      "Epoch 52/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.8150 - val_loss: 0.4178 - val_accuracy: 0.8110\n",
      "Epoch 53/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8065 - val_loss: 0.4166 - val_accuracy: 0.8095\n",
      "Epoch 54/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.8057 - val_loss: 0.4140 - val_accuracy: 0.8105\n",
      "Epoch 55/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.8046 - val_loss: 0.4128 - val_accuracy: 0.8110\n",
      "Epoch 56/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8026 - val_loss: 0.4157 - val_accuracy: 0.8085\n",
      "Epoch 57/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8142 - val_loss: 0.4132 - val_accuracy: 0.8130\n",
      "Epoch 58/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.8089 - val_loss: 0.4133 - val_accuracy: 0.8085\n",
      "Epoch 59/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8048 - val_loss: 0.4170 - val_accuracy: 0.8085\n",
      "Epoch 60/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8063 - val_loss: 0.4071 - val_accuracy: 0.8110\n",
      "Epoch 61/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7984 - val_loss: 0.4098 - val_accuracy: 0.8135\n",
      "Epoch 62/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.8015 - val_loss: 0.4101 - val_accuracy: 0.8110\n",
      "Epoch 63/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8060 - val_loss: 0.4100 - val_accuracy: 0.8085\n",
      "Epoch 64/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.8028 - val_loss: 0.4077 - val_accuracy: 0.8100\n",
      "Epoch 65/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.8060 - val_loss: 0.4081 - val_accuracy: 0.8085\n",
      "Epoch 66/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.8096 - val_loss: 0.4081 - val_accuracy: 0.8135\n",
      "Epoch 67/300\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.8065 - val_loss: 0.4082 - val_accuracy: 0.8095\n",
      "Epoch 68/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.8049 - val_loss: 0.4090 - val_accuracy: 0.8100\n",
      "Epoch 69/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8016 - val_loss: 0.4045 - val_accuracy: 0.8105\n",
      "Epoch 70/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.8004 - val_loss: 0.4045 - val_accuracy: 0.8120\n",
      "Epoch 71/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.8039 - val_loss: 0.4052 - val_accuracy: 0.8110\n",
      "Epoch 72/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.8061 - val_loss: 0.4035 - val_accuracy: 0.8140\n",
      "Epoch 73/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.8032 - val_loss: 0.4024 - val_accuracy: 0.8130\n",
      "Epoch 74/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8041 - val_loss: 0.4005 - val_accuracy: 0.8135\n",
      "Epoch 75/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8139 - val_loss: 0.4020 - val_accuracy: 0.8165\n",
      "Epoch 76/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.8026 - val_loss: 0.4032 - val_accuracy: 0.8145\n",
      "Epoch 77/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8077 - val_loss: 0.4014 - val_accuracy: 0.8180\n",
      "Epoch 78/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8021 - val_loss: 0.3985 - val_accuracy: 0.8175\n",
      "Epoch 79/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8022 - val_loss: 0.3981 - val_accuracy: 0.8165\n",
      "Epoch 80/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7989 - val_loss: 0.3989 - val_accuracy: 0.8160\n",
      "Epoch 81/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8068 - val_loss: 0.4002 - val_accuracy: 0.8170\n",
      "Epoch 82/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8126 - val_loss: 0.3990 - val_accuracy: 0.8175\n",
      "Epoch 83/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8001 - val_loss: 0.3999 - val_accuracy: 0.8180\n",
      "Epoch 84/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8049 - val_loss: 0.4009 - val_accuracy: 0.8195\n",
      "Epoch 85/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.8003 - val_loss: 0.3973 - val_accuracy: 0.8185\n",
      "Epoch 86/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.8087 - val_loss: 0.3988 - val_accuracy: 0.8200\n",
      "Epoch 87/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.8051 - val_loss: 0.3921 - val_accuracy: 0.8225\n",
      "Epoch 88/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.8084 - val_loss: 0.3951 - val_accuracy: 0.8175\n",
      "Epoch 89/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.8088 - val_loss: 0.3993 - val_accuracy: 0.8200\n",
      "Epoch 90/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8059 - val_loss: 0.3986 - val_accuracy: 0.8190\n",
      "Epoch 91/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8060 - val_loss: 0.3948 - val_accuracy: 0.8200\n",
      "Epoch 92/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8159 - val_loss: 0.3931 - val_accuracy: 0.8240\n",
      "Epoch 93/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.8007 - val_loss: 0.3933 - val_accuracy: 0.8200\n",
      "Epoch 94/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.8057 - val_loss: 0.3924 - val_accuracy: 0.8205\n",
      "Epoch 95/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.8018 - val_loss: 0.3916 - val_accuracy: 0.8220\n",
      "Epoch 96/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8103 - val_loss: 0.3928 - val_accuracy: 0.8210\n",
      "Epoch 97/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8136 - val_loss: 0.3966 - val_accuracy: 0.8190\n",
      "Epoch 98/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8058 - val_loss: 0.3922 - val_accuracy: 0.8205\n",
      "Epoch 99/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8039 - val_loss: 0.3930 - val_accuracy: 0.8185\n",
      "Epoch 100/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.8077 - val_loss: 0.3914 - val_accuracy: 0.8225\n",
      "Epoch 101/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8067 - val_loss: 0.3946 - val_accuracy: 0.8200\n",
      "Epoch 102/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8061 - val_loss: 0.3912 - val_accuracy: 0.8205\n",
      "Epoch 103/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.8107 - val_loss: 0.3895 - val_accuracy: 0.8215\n",
      "Epoch 104/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.8006 - val_loss: 0.3916 - val_accuracy: 0.8210\n",
      "Epoch 105/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8101 - val_loss: 0.3873 - val_accuracy: 0.8245\n",
      "Epoch 106/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8090 - val_loss: 0.3884 - val_accuracy: 0.8235\n",
      "Epoch 107/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8078 - val_loss: 0.3929 - val_accuracy: 0.8250\n",
      "Epoch 108/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8048 - val_loss: 0.3894 - val_accuracy: 0.8220\n",
      "Epoch 109/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8151 - val_loss: 0.3897 - val_accuracy: 0.8210\n",
      "Epoch 110/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8069 - val_loss: 0.3938 - val_accuracy: 0.8215\n",
      "Epoch 111/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8047 - val_loss: 0.3924 - val_accuracy: 0.8240\n",
      "Epoch 112/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8001 - val_loss: 0.3861 - val_accuracy: 0.8225\n",
      "Epoch 113/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8112 - val_loss: 0.3931 - val_accuracy: 0.8205\n",
      "Epoch 114/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8042 - val_loss: 0.3875 - val_accuracy: 0.8220\n",
      "Epoch 115/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8066 - val_loss: 0.3928 - val_accuracy: 0.8205\n",
      "Epoch 116/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.8009 - val_loss: 0.3911 - val_accuracy: 0.8220\n",
      "Epoch 117/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8076 - val_loss: 0.3899 - val_accuracy: 0.8220\n",
      "Epoch 118/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.8089 - val_loss: 0.3909 - val_accuracy: 0.8260\n",
      "Epoch 119/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.8106 - val_loss: 0.3889 - val_accuracy: 0.8235\n",
      "Epoch 120/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8019 - val_loss: 0.3901 - val_accuracy: 0.8210\n",
      "Epoch 121/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.8118 - val_loss: 0.3888 - val_accuracy: 0.8240\n",
      "Epoch 122/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7981 - val_loss: 0.3897 - val_accuracy: 0.8210\n",
      "Epoch 123/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8141 - val_loss: 0.3932 - val_accuracy: 0.8220\n",
      "Epoch 124/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.8046 - val_loss: 0.3883 - val_accuracy: 0.8210\n",
      "Epoch 125/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.8100 - val_loss: 0.3945 - val_accuracy: 0.8210\n",
      "Epoch 126/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8090 - val_loss: 0.3923 - val_accuracy: 0.8240\n",
      "Epoch 127/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.8051 - val_loss: 0.3976 - val_accuracy: 0.8190\n",
      "Epoch 128/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.8095 - val_loss: 0.3935 - val_accuracy: 0.8205\n",
      "Epoch 129/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.8079 - val_loss: 0.3975 - val_accuracy: 0.8205\n",
      "Epoch 130/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8067 - val_loss: 0.3947 - val_accuracy: 0.8200\n",
      "Epoch 131/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8086 - val_loss: 0.3878 - val_accuracy: 0.8200\n",
      "Epoch 132/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8100 - val_loss: 0.3930 - val_accuracy: 0.8230\n",
      "Epoch 133/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8093 - val_loss: 0.3924 - val_accuracy: 0.8225\n",
      "Epoch 134/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8088 - val_loss: 0.3910 - val_accuracy: 0.8240\n",
      "Epoch 135/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.8105 - val_loss: 0.3890 - val_accuracy: 0.8245\n",
      "Epoch 136/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8000 - val_loss: 0.3894 - val_accuracy: 0.8195\n",
      "Epoch 137/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.8044 - val_loss: 0.3864 - val_accuracy: 0.8210\n",
      "Epoch 138/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8118 - val_loss: 0.3870 - val_accuracy: 0.8235\n",
      "Epoch 139/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8108 - val_loss: 0.3913 - val_accuracy: 0.8205\n",
      "Epoch 140/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4474 - accuracy: 0.8141 - val_loss: 0.3898 - val_accuracy: 0.8240\n",
      "Epoch 141/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8073 - val_loss: 0.3878 - val_accuracy: 0.8215\n",
      "Epoch 142/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7973 - val_loss: 0.3931 - val_accuracy: 0.8250\n",
      "Epoch 143/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8064 - val_loss: 0.3871 - val_accuracy: 0.8210\n",
      "Epoch 144/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8030 - val_loss: 0.3865 - val_accuracy: 0.8205\n",
      "Epoch 145/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.8109 - val_loss: 0.3876 - val_accuracy: 0.8215\n",
      "Epoch 146/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7956 - val_loss: 0.3883 - val_accuracy: 0.8205\n",
      "Epoch 147/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.8027 - val_loss: 0.3890 - val_accuracy: 0.8215\n",
      "Epoch 148/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8144 - val_loss: 0.3888 - val_accuracy: 0.8245\n",
      "Epoch 149/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8132 - val_loss: 0.3872 - val_accuracy: 0.8240\n",
      "Epoch 150/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8049 - val_loss: 0.3869 - val_accuracy: 0.8225\n",
      "Epoch 151/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7977 - val_loss: 0.3901 - val_accuracy: 0.8205\n",
      "Epoch 152/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8038 - val_loss: 0.3865 - val_accuracy: 0.8240\n",
      "Epoch 153/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.8014 - val_loss: 0.3877 - val_accuracy: 0.8240\n",
      "Epoch 154/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7976 - val_loss: 0.3845 - val_accuracy: 0.8275\n",
      "Epoch 155/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8060 - val_loss: 0.3886 - val_accuracy: 0.8270\n",
      "Epoch 156/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.8058 - val_loss: 0.3858 - val_accuracy: 0.8280\n",
      "Epoch 157/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8085 - val_loss: 0.3922 - val_accuracy: 0.8225\n",
      "Epoch 158/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8116 - val_loss: 0.3897 - val_accuracy: 0.8240\n",
      "Epoch 159/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8076 - val_loss: 0.3872 - val_accuracy: 0.8250\n",
      "Epoch 160/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8016 - val_loss: 0.3914 - val_accuracy: 0.8205\n",
      "Epoch 161/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.8098 - val_loss: 0.3870 - val_accuracy: 0.8210\n",
      "Epoch 162/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8140 - val_loss: 0.3917 - val_accuracy: 0.8215\n",
      "Epoch 163/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8068 - val_loss: 0.3871 - val_accuracy: 0.8205\n",
      "Epoch 164/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8076 - val_loss: 0.3928 - val_accuracy: 0.8210\n",
      "Epoch 165/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8029 - val_loss: 0.3880 - val_accuracy: 0.8215\n",
      "Epoch 166/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8070 - val_loss: 0.3917 - val_accuracy: 0.8205\n",
      "Epoch 167/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8068 - val_loss: 0.3861 - val_accuracy: 0.8215\n",
      "Epoch 168/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8137 - val_loss: 0.3911 - val_accuracy: 0.8225\n",
      "Epoch 169/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8052 - val_loss: 0.3851 - val_accuracy: 0.8215\n",
      "Epoch 170/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.8037 - val_loss: 0.3876 - val_accuracy: 0.8210\n",
      "Epoch 171/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8088 - val_loss: 0.3855 - val_accuracy: 0.8210\n",
      "Epoch 172/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.8016 - val_loss: 0.3865 - val_accuracy: 0.8225\n",
      "Epoch 173/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8118 - val_loss: 0.3920 - val_accuracy: 0.8230\n",
      "Epoch 174/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8038 - val_loss: 0.3896 - val_accuracy: 0.8200\n",
      "Epoch 175/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8029 - val_loss: 0.3861 - val_accuracy: 0.8230\n",
      "Epoch 176/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8037 - val_loss: 0.3859 - val_accuracy: 0.8200\n",
      "Epoch 177/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7983 - val_loss: 0.3907 - val_accuracy: 0.8205\n",
      "Epoch 178/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.8086 - val_loss: 0.3867 - val_accuracy: 0.8215\n",
      "Epoch 179/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7981 - val_loss: 0.3896 - val_accuracy: 0.8210\n",
      "Epoch 180/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.8167 - val_loss: 0.3903 - val_accuracy: 0.8215\n",
      "Epoch 181/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8069 - val_loss: 0.3900 - val_accuracy: 0.8215\n",
      "Epoch 182/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4508 - accuracy: 0.8062 - val_loss: 0.3871 - val_accuracy: 0.8205\n",
      "Epoch 183/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8085 - val_loss: 0.3868 - val_accuracy: 0.8215\n",
      "Epoch 184/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8115 - val_loss: 0.3838 - val_accuracy: 0.8240\n",
      "Epoch 185/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8052 - val_loss: 0.3881 - val_accuracy: 0.8225\n",
      "Epoch 186/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4444 - accuracy: 0.8106 - val_loss: 0.3885 - val_accuracy: 0.8210\n",
      "Epoch 187/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8144 - val_loss: 0.3906 - val_accuracy: 0.8195\n",
      "Epoch 188/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8158 - val_loss: 0.3833 - val_accuracy: 0.8215\n",
      "Epoch 189/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7977 - val_loss: 0.3927 - val_accuracy: 0.8210\n",
      "Epoch 190/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8118 - val_loss: 0.3837 - val_accuracy: 0.8235\n",
      "Epoch 191/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8062 - val_loss: 0.3915 - val_accuracy: 0.8215\n",
      "Epoch 192/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8043 - val_loss: 0.3842 - val_accuracy: 0.8215\n",
      "Epoch 193/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.8142 - val_loss: 0.3894 - val_accuracy: 0.8215\n",
      "Epoch 194/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8127 - val_loss: 0.3870 - val_accuracy: 0.8225\n",
      "Epoch 195/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8154 - val_loss: 0.3873 - val_accuracy: 0.8205\n",
      "Epoch 196/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8099 - val_loss: 0.3845 - val_accuracy: 0.8220\n",
      "Epoch 197/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8106 - val_loss: 0.3850 - val_accuracy: 0.8210\n",
      "Epoch 198/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.8069 - val_loss: 0.3864 - val_accuracy: 0.8220\n",
      "Epoch 199/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.8064 - val_loss: 0.3868 - val_accuracy: 0.8210\n",
      "Epoch 200/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.8149 - val_loss: 0.3848 - val_accuracy: 0.8235\n",
      "Epoch 201/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.8108 - val_loss: 0.3842 - val_accuracy: 0.8215\n",
      "Epoch 202/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7993 - val_loss: 0.3844 - val_accuracy: 0.8220\n",
      "Epoch 203/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.8095 - val_loss: 0.3831 - val_accuracy: 0.8240\n",
      "Epoch 204/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.8137 - val_loss: 0.3883 - val_accuracy: 0.8245\n",
      "Epoch 205/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8067 - val_loss: 0.3907 - val_accuracy: 0.8210\n",
      "Epoch 206/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8041 - val_loss: 0.3894 - val_accuracy: 0.8210\n",
      "Epoch 207/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8075 - val_loss: 0.3872 - val_accuracy: 0.8215\n",
      "Epoch 208/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8093 - val_loss: 0.3839 - val_accuracy: 0.8220\n",
      "Epoch 209/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8083 - val_loss: 0.3840 - val_accuracy: 0.8230\n",
      "Epoch 210/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8094 - val_loss: 0.3914 - val_accuracy: 0.8195\n",
      "Epoch 211/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8137 - val_loss: 0.3833 - val_accuracy: 0.8230\n",
      "Epoch 212/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4520 - accuracy: 0.8047 - val_loss: 0.3845 - val_accuracy: 0.8225\n",
      "Epoch 213/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.8082 - val_loss: 0.3852 - val_accuracy: 0.8230\n",
      "Epoch 214/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8115 - val_loss: 0.3854 - val_accuracy: 0.8230\n",
      "Epoch 215/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8042 - val_loss: 0.3839 - val_accuracy: 0.8210\n",
      "Epoch 216/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.8059 - val_loss: 0.3845 - val_accuracy: 0.8235\n",
      "Epoch 217/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8091 - val_loss: 0.3905 - val_accuracy: 0.8210\n",
      "Epoch 218/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.8044 - val_loss: 0.3879 - val_accuracy: 0.8215\n",
      "Epoch 219/300\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4469 - accuracy: 0.8076 - val_loss: 0.3861 - val_accuracy: 0.8215\n",
      "Epoch 220/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.8086 - val_loss: 0.3838 - val_accuracy: 0.8230\n",
      "Epoch 221/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.8080 - val_loss: 0.3832 - val_accuracy: 0.8220\n",
      "Epoch 222/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.8142 - val_loss: 0.3873 - val_accuracy: 0.8225\n",
      "Epoch 223/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8126 - val_loss: 0.3845 - val_accuracy: 0.8250\n",
      "Epoch 224/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8141 - val_loss: 0.3851 - val_accuracy: 0.8220\n",
      "Epoch 225/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.8029 - val_loss: 0.3820 - val_accuracy: 0.8280\n",
      "Epoch 226/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8070 - val_loss: 0.3826 - val_accuracy: 0.8230\n",
      "Epoch 227/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8085 - val_loss: 0.3883 - val_accuracy: 0.8220\n",
      "Epoch 228/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8093 - val_loss: 0.3885 - val_accuracy: 0.8220\n",
      "Epoch 229/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8063 - val_loss: 0.3893 - val_accuracy: 0.8235\n",
      "Epoch 230/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8066 - val_loss: 0.3876 - val_accuracy: 0.8205\n",
      "Epoch 231/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8105 - val_loss: 0.3846 - val_accuracy: 0.8235\n",
      "Epoch 232/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4510 - accuracy: 0.8115 - val_loss: 0.3897 - val_accuracy: 0.8210\n",
      "Epoch 233/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4617 - accuracy: 0.7983 - val_loss: 0.3832 - val_accuracy: 0.8260\n",
      "Epoch 234/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4436 - accuracy: 0.8114 - val_loss: 0.3854 - val_accuracy: 0.8220\n",
      "Epoch 235/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4538 - accuracy: 0.8063 - val_loss: 0.3840 - val_accuracy: 0.8220\n",
      "Epoch 236/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4533 - accuracy: 0.8065 - val_loss: 0.3862 - val_accuracy: 0.8230\n",
      "Epoch 237/300\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4397 - accuracy: 0.8139 - val_loss: 0.3876 - val_accuracy: 0.8220\n",
      "Epoch 238/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4610 - accuracy: 0.8037 - val_loss: 0.3873 - val_accuracy: 0.8255\n",
      "Epoch 239/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4525 - accuracy: 0.8045 - val_loss: 0.3876 - val_accuracy: 0.8215\n",
      "Epoch 240/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4504 - accuracy: 0.8060 - val_loss: 0.3916 - val_accuracy: 0.8215\n",
      "Epoch 241/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8024 - val_loss: 0.3834 - val_accuracy: 0.8270\n",
      "Epoch 242/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.8051 - val_loss: 0.3877 - val_accuracy: 0.8215\n",
      "Epoch 243/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8101 - val_loss: 0.3868 - val_accuracy: 0.8220\n",
      "Epoch 244/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8090 - val_loss: 0.3872 - val_accuracy: 0.8190\n",
      "Epoch 245/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8032 - val_loss: 0.3856 - val_accuracy: 0.8210\n",
      "Epoch 246/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8090 - val_loss: 0.3871 - val_accuracy: 0.8230\n",
      "Epoch 247/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.8073 - val_loss: 0.3881 - val_accuracy: 0.8220\n",
      "Epoch 248/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.8061 - val_loss: 0.3849 - val_accuracy: 0.8215\n",
      "Epoch 249/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8083 - val_loss: 0.3891 - val_accuracy: 0.8220\n",
      "Epoch 250/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8012 - val_loss: 0.3871 - val_accuracy: 0.8220\n",
      "Epoch 251/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.8030 - val_loss: 0.3841 - val_accuracy: 0.8240\n",
      "Epoch 252/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8087 - val_loss: 0.3841 - val_accuracy: 0.8220\n",
      "Epoch 253/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8034 - val_loss: 0.3808 - val_accuracy: 0.8240\n",
      "Epoch 254/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8028 - val_loss: 0.3848 - val_accuracy: 0.8205\n",
      "Epoch 255/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8037 - val_loss: 0.3851 - val_accuracy: 0.8215\n",
      "Epoch 256/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8035 - val_loss: 0.3877 - val_accuracy: 0.8210\n",
      "Epoch 257/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8105 - val_loss: 0.3869 - val_accuracy: 0.8210\n",
      "Epoch 258/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.8126 - val_loss: 0.3912 - val_accuracy: 0.8200\n",
      "Epoch 259/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8093 - val_loss: 0.3871 - val_accuracy: 0.8230\n",
      "Epoch 260/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.8047 - val_loss: 0.3903 - val_accuracy: 0.8205\n",
      "Epoch 261/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4544 - accuracy: 0.8014 - val_loss: 0.3853 - val_accuracy: 0.8210\n",
      "Epoch 262/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8083 - val_loss: 0.3859 - val_accuracy: 0.8220\n",
      "Epoch 263/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8061 - val_loss: 0.3876 - val_accuracy: 0.8210\n",
      "Epoch 264/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8041 - val_loss: 0.3854 - val_accuracy: 0.8225\n",
      "Epoch 265/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8049 - val_loss: 0.3844 - val_accuracy: 0.8210\n",
      "Epoch 266/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7971 - val_loss: 0.3831 - val_accuracy: 0.8220\n",
      "Epoch 267/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8063 - val_loss: 0.3864 - val_accuracy: 0.8225\n",
      "Epoch 268/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.8034 - val_loss: 0.3813 - val_accuracy: 0.8250\n",
      "Epoch 269/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8077 - val_loss: 0.3866 - val_accuracy: 0.8215\n",
      "Epoch 270/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8105 - val_loss: 0.3847 - val_accuracy: 0.8230\n",
      "Epoch 271/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8115 - val_loss: 0.3887 - val_accuracy: 0.8215\n",
      "Epoch 272/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.8099 - val_loss: 0.3870 - val_accuracy: 0.8220\n",
      "Epoch 273/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.8092 - val_loss: 0.3871 - val_accuracy: 0.8215\n",
      "Epoch 274/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.8034 - val_loss: 0.3829 - val_accuracy: 0.8230\n",
      "Epoch 275/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4437 - accuracy: 0.8127 - val_loss: 0.3832 - val_accuracy: 0.8215\n",
      "Epoch 276/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8141 - val_loss: 0.3803 - val_accuracy: 0.8215\n",
      "Epoch 277/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.8044 - val_loss: 0.3855 - val_accuracy: 0.8220\n",
      "Epoch 278/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.8087 - val_loss: 0.3820 - val_accuracy: 0.8290\n",
      "Epoch 279/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8024 - val_loss: 0.3821 - val_accuracy: 0.8215\n",
      "Epoch 280/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8151 - val_loss: 0.3808 - val_accuracy: 0.8260\n",
      "Epoch 281/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.8150 - val_loss: 0.3854 - val_accuracy: 0.8230\n",
      "Epoch 282/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8110 - val_loss: 0.3869 - val_accuracy: 0.8225\n",
      "Epoch 283/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8086 - val_loss: 0.3839 - val_accuracy: 0.8220\n",
      "Epoch 284/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8087 - val_loss: 0.3889 - val_accuracy: 0.8250\n",
      "Epoch 285/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4468 - accuracy: 0.8085 - val_loss: 0.3834 - val_accuracy: 0.8210\n",
      "Epoch 286/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.8026 - val_loss: 0.3844 - val_accuracy: 0.8200\n",
      "Epoch 287/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4414 - accuracy: 0.8114 - val_loss: 0.3842 - val_accuracy: 0.8220\n",
      "Epoch 288/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.8066 - val_loss: 0.3890 - val_accuracy: 0.8185\n",
      "Epoch 289/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8042 - val_loss: 0.3869 - val_accuracy: 0.8195\n",
      "Epoch 290/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4515 - accuracy: 0.8024 - val_loss: 0.3895 - val_accuracy: 0.8255\n",
      "Epoch 291/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8123 - val_loss: 0.3831 - val_accuracy: 0.8220\n",
      "Epoch 292/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4540 - accuracy: 0.8026 - val_loss: 0.3859 - val_accuracy: 0.8225\n",
      "Epoch 293/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.8063 - val_loss: 0.3857 - val_accuracy: 0.8240\n",
      "Epoch 294/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.8011 - val_loss: 0.3793 - val_accuracy: 0.8245\n",
      "Epoch 295/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8093 - val_loss: 0.3824 - val_accuracy: 0.8255\n",
      "Epoch 296/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.8094 - val_loss: 0.3807 - val_accuracy: 0.8220\n",
      "Epoch 297/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8134 - val_loss: 0.3813 - val_accuracy: 0.8240\n",
      "Epoch 298/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.8052 - val_loss: 0.3878 - val_accuracy: 0.8195\n",
      "Epoch 299/300\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8124 - val_loss: 0.3847 - val_accuracy: 0.8215\n",
      "Epoch 300/300\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4466 - accuracy: 0.8073 - val_loss: 0.3826 - val_accuracy: 0.8245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2c268c2128>"
      ]
     },
     "execution_count": 126,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x=x_train,y=y_train,epochs=300,validation_data=(x_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "XxkkoKFumsDa",
    "outputId": "c68d5fd1-07c9-4e40-ba91-9dff89dc5591"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2c1d1fa588>"
      ]
     },
     "execution_count": 127,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model3.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wNhQGkKCprTu",
    "outputId": "e2f2531b-353d-4e1f-f015-06124de36d28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "#From above analysis we can say that model2 is giving better results than other two models\n",
    "pred=model2.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubcitmyP0iOv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sx_854IFsudF",
    "outputId": "9e5b0bcd-9c2a-4891-909a-61ed1677d69c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Second model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92      1616\n",
      "           1       0.81      0.40      0.54       384\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.84      0.69      0.73      2000\n",
      "weighted avg       0.86      0.87      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(\"For Second model\")\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrasUTbx0Q8O"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "dl_drill.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
